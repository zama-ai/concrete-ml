# This workflow is called by new_generation_benchmarks.yaml
name: Single benchmark

on:
  workflow_dispatch:
    inputs:
      instance_id:
        description: 'Instance ID'
        type: string
        required: true
      instance_image_id:
        description: 'Instance AMI ID'
        type: string
      instance_type:
        description: 'Instance product type'
        type: string
      runner_name:
        description: 'Action runner name'
        type: string
        required: true
      request_id:
        description: 'Slab request ID'
        type: string
      user_inputs:
        description: 'User inputs formatted as JSON string'
        type: string
        required: true

    secrets:
      NEW_ML_PROGRESS_TRACKER_TOKEN:
        description: "ML progress tracker token"
      NEW_ML_PROGRESS_TRACKER_URL:
        description: "ML progress tracker url"
      PIP_INDEX_URL:
        description: "pip index url"
      PIP_EXTRA_INDEX_URL:
        description: "Internal repo url"
      INTERNAL_PYPI_URL:
        description: "Internal pypi url"
      INTERNAL_REPO_URL:
        description: "Internal repo url"
      AWS_ACCESS_KEY_ID:
        description: "AWS access key"
      AWS_SECRET_ACCESS_KEY:
        description: "AWS secret key"
      AWS_REGION:
        description: "AWS region"
      BENCHMARKS_AWS_REGION:
        description: "AWS region"
      EC2_RUNNER_BOT_TOKEN:
        description: "EC2 Runner bot token"
      AWS_EC2_AMI:
        description: "AWS EC2 AMI"
      AWS_EC2_INSTANCE_TYPE:
        description: "AWS EC2 Instance type"
      AWS_EC2_SUBNET_ID:
        description: "AWS EC2 Subnet id"
      AWS_EC2_SECURITY_GROUP_ID:
        description: "AWS EC2 security group id"
      INTERNAL_PYPI_URL_FOR_MASK:
        description: "Used for masking"
      INTERNAL_REPO_URL_FOR_MASK:
        description: "Used for masking"

env:
  AGENT_TOOLSDIRECTORY: /opt/hostedtoolcache
  RUNNER_TOOL_CACHE: /opt/hostedtoolcache

jobs:
  run-command:
    name: Run benchmarks
    runs-on: ${{ inputs.runner_name }}
    if: ${{ !cancelled() }}
    container:
      image: ubuntu:20.04
    defaults:
      run:
        shell: bash
    env:
      PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
      PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
    steps:
      - name: Instance configuration used
        run: |
          echo "IDs: ${{ inputs.instance_id }}"
          echo "AMI: ${{ inputs.instance_image_id }}"
          echo "Type: ${{ inputs.instance_type }}"
          echo "Request ID: ${{ inputs.request_id }}"
          echo "Matrix item: ${{ inputs.matrix_item }}"
          echo "User inputs: ${{ inputs.user_inputs }}"

      - name: Add masks
        id: masks
        run: |
          echo "::add-mask::${{ secrets.INTERNAL_PYPI_URL_FOR_MASK }}"
          echo "::add-mask::${{ secrets.INTERNAL_REPO_URL_FOR_MASK }}"
          echo "::add-mask::${{ secrets.INTERNAL_PYPI_URL }}"
          echo "::add-mask::${{ secrets.INTERNAL_REPO_URL }}"

      - name: Docker container related setup and git installation
        id: docker-git-config
        run: |
          TZ=Europe/Paris
          echo "TZ=${TZ}" >> "$GITHUB_ENV"
          ln -snf /usr/share/zoneinfo/${TZ} /etc/localtime && echo ${TZ} > /etc/timezone
          sed -i 's|^deb http://archive|deb http://fr.archive|g' /etc/apt/sources.list
          apt update && apt install git git-lfs -y
          apt -y install sudo

      # Run with current version
      - name: Checkout CML to run
        uses: actions/checkout@8ade135a41bc03ea155e62e844d188df1ea18608
        with:
          fetch-depth: 1
          lfs: true
          path: cml_to_run

      - name: Sanitize Python commands
        run: |
          cd ./cml_to_run
          apt install -y python3
          USER_INPUTS=$(echo ${{ inputs.user_inputs }})
          echo USER_INPUTS=$(python3 script/actions_utils/escape_quotes.py "$USER_INPUTS") >> "$GITHUB_ENV"

      # Install specific version
      # Also pull LFS files (for example, for pulling the pre-trained deep learning model weights)
      - name: Checkout CML to install
        uses: actions/checkout@8ade135a41bc03ea155e62e844d188df1ea18608
        with:
          fetch-depth: 1
          lfs: true
          ref: ${{ fromJSON(env.USER_INPUTS).git-ref }}
          path: cml_to_install

      - name: Set up Python
        uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1
        with:
          python-version: "3.9"

      - name: Install dependencies
        id: install-deps
        uses: nick-fields/retry@v2
        with:
          max_attempts: 5
          timeout_minutes: 20
          retry_wait_seconds: 5
          shell: bash
          command: |
            cd ./cml_to_install
            # The python-dev version should be in sync with the one from the previous step
            apt-get install --no-install-recommends -y gnome-keyring
            apt install -y graphviz* graphviz-dev libgraphviz-dev pkg-config python3.9-dev
            apt-mark hold docker.io
            ./script/make_utils/setup_os_deps.sh
            # Needed for some reason
            make setup_env
            source ./.venv/bin/activate
            python -m pip show concrete-numpy

      # Now we get our most up to date version
      - name: Run the benchmark command
        # 34 days * 24 hours * 60 minutes 
        # Workflow limit is 35 days
        # No apparent limit on job/step time
        # https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners#usage-limits
        timeout-minutes: 48960
        id: run-benchmark
        shell: bash
        run: |
          source ./cml_to_install/.venv/bin/activate
          cd ./cml_to_run
          python3 script/actions_utils/escape_quotes.py --curly-braces-only """$(echo ${{ fromJSON(env.USER_INPUTS).commands }})""" | sed 's|\\\\||g' >> commands.json
          python ./script/actions_utils/run_commands.py --file commands.json

      - name: Convert progress.json
        id: convert-output
        run: |
          source ./cml_to_install/.venv/bin/activate
          python ./cml_to_run/benchmarks/convert.py --source ./cml_to_run/progress.json --target ./converted.json --path_to_repository ./cml_to_install --machine_name "${{ github.event.inputs.instance_type }}"
          cat ./converted.json | jq

      - name: Upload results
        id: upload-results
        run: |
          curl \
          -H "Authorization: Bearer ${{ secrets.NEW_ML_PROGRESS_TRACKER_TOKEN }}" \
          -H "Content-Type: application/json" \
          -d @converted.json \
          -X POST "${{ secrets.NEW_ML_PROGRESS_TRACKER_URL }}experiment"
