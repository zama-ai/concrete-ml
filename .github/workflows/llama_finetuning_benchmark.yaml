# TODO: Remove pull_request trigger before merging to main
name: LLama Fine-tuning Benchmark CML
on:
  schedule:
    - cron: '0 0 1 * *'
  pull_request:
  workflow_dispatch:
    inputs:
      git-ref:
        description: Repo reference (branch, tag or SHA)
        default: "main"
        required: true
        type: string
      alternative-cp-wheel-artifact-id:
        description: Alternative Concrete-Python Wheel Artifact-ID (see https://github.com/zama-ai/concrete/actions/workflows/concrete_python_release.yml)
        default: "none"
        required: true
        type: string
      alternative-cp-branch:
        description: Alternative Concrete-Python Branch
        default: "none"
        required: true
        type: string
      mode:
        description: Training mode (torch, 7bit, or 16bit)
        default: "7bit"
        type: choice
        options:
          - "torch"
          - "7bit"
          - "16bit"
      fhe-mode:
        description: FHE execution mode (disable, simulate, or execute)
        default: "execute"
        type: choice
        options:
          - "disable"
          - "simulate"
          - "execute"
      max_length:
        description: Maximum sequence length
        default: "64"
        type: string
        required: true
      batch_size:
        description: Batch size for training
        default: "1"
        type: string
        required: true
      training_steps:
        description: Number of training steps to run
        default: "5"
        type: string
        required: true

permissions:
  contents: read

# Global environment variables
env:
  ACTION_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
  AGENT_TOOLSDIRECTORY: /opt/hostedtoolcache
  RUNNER_TOOL_CACHE: /opt/hostedtoolcache

# Jobs
jobs:
  setup-instances:
    name: Setup EC2 instances
    runs-on: ubuntu-24.04
    strategy:
      matrix:
        device:
          - type: cpu
            profile: big-cpu
          - type: gpu
            profile: a10gpu
    outputs:
      cpu-runner: ${{ steps.set-outputs.outputs.cpu-runner }}
      gpu-runner: ${{ steps.set-outputs.outputs.gpu-runner }}
    steps:
      - name: Start ${{ matrix.device.type }} instance
        id: start-instance
        uses: zama-ai/slab-github-runner@79939325c3c429837c10d6041e4fd8589d328bac
        with:
          mode: start
          github-token: ${{ secrets.SLAB_ACTION_TOKEN }}
          slab-url: ${{ secrets.SLAB_BASE_URL }}
          job-secret: ${{ secrets.JOB_SECRET }}
          backend: aws
          profile: ${{ matrix.device.profile }}

      - name: Set outputs
        id: set-outputs
        run: |
          if [ "${{ matrix.device.type }}" == "cpu" ]; then
            echo "cpu-runner=${{ steps.start-instance.outputs.label }}" >> $GITHUB_OUTPUT
          else
            echo "gpu-runner=${{ steps.start-instance.outputs.label }}" >> $GITHUB_OUTPUT
          fi

  run-benchmark:
    needs: [setup-instances]
    name: Run LLama LoRA Math benchmark on ${{ matrix.device }}
    strategy:
      fail-fast: false  # Prevents cancellation of in-progress matrix jobs when one fails
      matrix:
        device: [cpu, gpu]
    runs-on: ${{ matrix.device == 'cpu' && needs.setup-instances.outputs.cpu-runner || needs.setup-instances.outputs.gpu-runner }}
    outputs:
      cpu-status: ${{ steps.set-status.outputs.cpu-status }}
      gpu-status: ${{ steps.set-status.outputs.gpu-status }}
    env:
      PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
      MAX_LENGTH: ${{ github.event.inputs.max_length || '64' }}
      BATCH_SIZE: ${{ github.event.inputs.batch_size || '1' }}
      TRAINING_STEPS: ${{ github.event.inputs.training_steps || '5' }}
      MODE: ${{ github.event.inputs.mode || '7bit' }}
      FHE_MODE: ${{ github.event.inputs.fhe-mode || 'execute' }}
    steps:
      - name: Add masks
        run: |
          echo "::add-mask::${{ secrets.INTERNAL_PYPI_URL_FOR_MASK }}"
          echo "::add-mask::${{ secrets.INTERNAL_REPO_URL_FOR_MASK }}"
          echo "::add-mask::${{ secrets.INTERNAL_PYPI_URL }}"
          echo "::add-mask::${{ secrets.INTERNAL_REPO_URL }}"

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: 'false'
          lfs: true
          ref: ${{ github.event.inputs.git-ref }}

      - name: Set up Python
        uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38
        with:
          python-version: "3.8"

      - name: Install dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install --no-install-recommends -y \
            gnome-keyring \
            graphviz \
            graphviz-dev \
            libgraphviz-dev \
            pkg-config \
            python3-dev
          sudo apt-mark hold docker.io
          ./script/make_utils/setup_os_deps.sh
          make setup_env
          source .venv/bin/activate
          

          if [ "${{ matrix.device }}" == "gpu" ]; then
            pip install torch>=2.0.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
          else
            pip install torch>=2.0.0
          fi
          
          pip install transformers>=4.30.0 datasets>=2.12.0 peft>=0.4.0 tqdm>=4.65.0 numpy>=1.24.0 psutil>=5.9.0 py-cpuinfo>=9.0.0 accelerate>=1.1.0

      - name: Alternative Concrete Python Wheel Download
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.alternative-cp-wheel-artifact-id != 'none'
        run: |
          curl -L \
          -H "Accept: application/vnd.github+json" \
          -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
          -H "X-GitHub-Api-Version: 2022-11-28" \
          -o concrete-python.whl.zip \
          https://api.github.com/repos/zama-ai/concrete/actions/artifacts/${{ github.event.inputs.alternative-cp-wheel-artifact-id }}/zip

      - name: Alternative Concrete Python Wheel Install
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.alternative-cp-wheel-artifact-id != 'none'
        run: |
          source .venv/bin/activate
          unzip concrete-python.whl.zip
          pip install concrete_python-*.whl

      - name: Alternative Concrete Python Branch Checkout
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.alternative-cp-branch != 'none'
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: 'false'
          path: concrete
          repository: zama-ai/concrete
          ref: ${{ github.event.inputs.alternative-cp-branch }}

      - name: Alternative Concrete Python Branch Source Install
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.alternative-cp-branch != 'none'
        run: |
          cp -R concrete/frontends/concrete-python/concrete/* .venv/lib/python3.*/site-packages/concrete/

      - name: Run Benchmark - LLama LoRA Math Word Problems (${{ matrix.device }})
        id: run-benchmark
        run: |
          source .venv/bin/activate
          
          # Login to Hugging Face
          huggingface-cli login --token ${{ secrets.LLAMA_HF_TOKEN }}
          
          # Run benchmark with appropriate device flag
          if [ "${{ matrix.device }}" == "cpu" ]; then
            python3 benchmarks/llama_lora_math_benchmark.py --save-model --device-type cpu
          else
            python3 benchmarks/llama_lora_math_benchmark.py --save-model --device-type gpu
          fi

      - name: Check if metrics exist
        id: check-metrics
        if: always()
        run: |
          if [ -f "to_upload.json" ]; then
            echo "metrics-exist=true" >> $GITHUB_OUTPUT
          else
            echo "metrics-exist=false" >> $GITHUB_OUTPUT
          fi

      - name: Archive metrics
        if: always() && steps.check-metrics.outputs.metrics-exist == 'true'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: metrics-${{ matrix.device }}.json
          path: to_upload.json

      - name: Check if model exists
        id: check-model
        if: always()
        run: |
          if [ -d "deployment/llama_lora_finetuned_${{ github.event.inputs.mode }}" ]; then
            echo "model-exist=true" >> $GITHUB_OUTPUT
          else
            echo "model-exist=false" >> $GITHUB_OUTPUT
          fi

      - name: Archive fine-tuned model
        if: always() && steps.check-model.outputs.model-exist == 'true'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: llama_lora_finetuned_${{ github.event.inputs.mode }}_${{ matrix.device }}
          path: deployment/llama_lora_finetuned_${{ github.event.inputs.mode }}

      - name: Upload results to benchmark database
        if: |
          always() && 
          steps.check-metrics.outputs.metrics-exist == 'true' &&
          github.event.inputs.alternative-cp-branch == 'none' && 
          github.event.inputs.alternative-cp-wheel-artifact-id == 'none'
        run: |
          # Log the json
          cat to_upload.json | jq
          
          # Wait to avoid log issues
          sleep 1
          
          # Upload to benchmark database
          curl --fail-with-body \
          -H "Authorization: Bearer ${{ secrets.NEW_ML_PROGRESS_TRACKER_TOKEN }}" \
          -H "Content-Type: application/json; charset=UTF-8" \
          -d @to_upload.json \
          -X POST "${{ secrets.NEW_ML_PROGRESS_TRACKER_URL }}experiment"

      - name: Set job status output
        id: set-status
        if: always()
        run: |
          if [ "${{ matrix.device }}" == "cpu" ]; then
            echo "cpu-status=${{ steps.run-benchmark.outcome }}" >> $GITHUB_OUTPUT
          else
            echo "gpu-status=${{ steps.run-benchmark.outcome }}" >> $GITHUB_OUTPUT
          fi

  teardown-instances:
    name: Teardown EC2 instances
    if: ${{ always() }}
    needs: [setup-instances, run-benchmark]
    runs-on: ubuntu-24.04
    strategy:
      matrix:
        device:
          - type: cpu
            runner: ${{ needs.setup-instances.outputs.cpu-runner }}
          - type: gpu
            runner: ${{ needs.setup-instances.outputs.gpu-runner }}
    steps:
      - name: Stop ${{ matrix.device.type }} instance
        uses: zama-ai/slab-github-runner@79939325c3c429837c10d6041e4fd8589d328bac
        with:
          mode: stop
          github-token: ${{ secrets.SLAB_ACTION_TOKEN }}
          slab-url: ${{ secrets.SLAB_BASE_URL }}
          job-secret: ${{ secrets.JOB_SECRET }}
          label: ${{ matrix.device.runner }}

  slack-notification:
    runs-on: ubuntu-24.04
    needs: [run-benchmark]
    if: |
      always() && 
      github.event.inputs.alternative-cp-branch == 'none' && 
      github.event.inputs.alternative-cp-wheel-artifact-id == 'none'
    steps:
      - name: Determine overall status
        id: overall-status
        run: |
          # Get the overall job status
          if [ "${{ needs.run-benchmark.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          elif [ "${{ needs.run-benchmark.result }}" == "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          else
            echo "status=partial" >> $GITHUB_OUTPUT
            echo "color=warning" >> $GITHUB_OUTPUT
          fi

      - name: Slack Notification
        continue-on-error: true
        uses: rtCamp/action-slack-notify@c33737706dea87cd7784c687dadc9adf1be59990
        env:
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL }}
          SLACK_ICON: https://pbs.twimg.com/profile_images/1274014582265298945/OjBKP9kn_400x400.png
          SLACK_COLOR: ${{ steps.overall-status.outputs.color }}
          SLACK_MESSAGE: "LLama LoRA Math benchmark - mode: ${{ github.event.inputs.mode }}, fhe: ${{ github.event.inputs.fhe-mode }} (CPU & GPU) - Status: ${{ steps.overall-status.outputs.status }} (${{ env.ACTION_RUN_URL }})"
          SLACK_USERNAME: ${{ secrets.BOT_USERNAME }}
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}