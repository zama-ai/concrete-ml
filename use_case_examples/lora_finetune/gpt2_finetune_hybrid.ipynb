{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lora_module import LoraTraining\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from remote_module import CustomConv1D\n",
    "from torch.nn import Embedding\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Conv1D,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from concrete.ml.torch.hybrid_model import HybridFHEModel\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Freeze weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, model, tokenizer, max_new_tokens=30):\n",
    "    # Encode the input prompt\n",
    "    inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is FHE? FH: A basic program that is used to calculate the height of an object, and then sets the minimum height to be the object's height.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"What is FHE ?\"\n",
    "generated_text = generate_text(prompt, model, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_conv1d(module, module_index_to_skip=0):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, Conv1D):\n",
    "\n",
    "            # Skip the module if the index has not been reached, and decrement the index\n",
    "            if module_index_to_skip >= 0:\n",
    "                module_index_to_skip -= 1\n",
    "            else:\n",
    "                custom_linear = CustomConv1D(child.weight, bias=child.bias)\n",
    "                setattr(module, name, custom_linear)\n",
    "        else:\n",
    "            module_index_to_skip = replace_conv1d(child, module_index_to_skip=module_index_to_skip)\n",
    "\n",
    "    return module_index_to_skip\n",
    "\n",
    "\n",
    "# Gradients of the first base layer that is used for fine-tuning are not needed. We\n",
    "# therefore need to exclude the backward module from the remote_names since calibration\n",
    "# won't get through it (which raises an issue with hybrid models)\n",
    "replace_conv1d(peft_model, module_index_to_skip=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "\n",
    "lora_training = LoraTraining(peft_model, GRADIENT_ACCUMULATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 128\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data_finetune/what_is_fhe.txt\",\n",
    "    block_size=BLOCK_SIZE,\n",
    "    cache_dir=\"cache_dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "EPOCHS = 100\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    save_total_limit=1,\n",
    "    use_cpu=True,\n",
    "    learning_rate=5e-4,\n",
    "    logging_strategy=\"epoch\",\n",
    "    optim=\"adamw_torch\",\n",
    "    seed=SEED,\n",
    "    data_seed=SEED,\n",
    "    weight_decay=0.0,\n",
    "    warmup_steps=0,\n",
    "    max_grad_norm=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "train_dataloader = trainer.get_train_dataloader()\n",
    "\n",
    "len_dataloader = len(train_dataloader)\n",
    "num_update_steps_per_epoch = len_dataloader // training_args.gradient_accumulation_steps\n",
    "num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
    "max_steps = math.ceil(training_args.num_train_epochs * num_update_steps_per_epoch)\n",
    "\n",
    "trainer.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
    "\n",
    "lora_training.update_training_parameters(trainer.optimizer, trainer.lr_scheduler, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remote_names(model, include_embedding_layers=False):\n",
    "    remote_names = []\n",
    "    for name, module in model.named_modules():\n",
    "        # Some gradients are not needed for fine-tuning, so need to exclude the backward module\n",
    "        # from the remote_names since calibration won't get through it (which raises an issue with\n",
    "        # hybrid models). We however still need to include the associated module's forward pass in\n",
    "        # the hybrid model\n",
    "        # We can also include the embedding and language model head as they represent a lot of the\n",
    "        # model's parameters. Side note: \"lm_head\" does not appear in model.parameters() because\n",
    "        # the weights are directly tied to the embedding ones, but we still need to remove both\n",
    "        # modules in order to get rid of the weights\n",
    "        if (\n",
    "            isinstance(module, Conv1D)\n",
    "            or include_embedding_layers\n",
    "            and (isinstance(module, Embedding) or \"lm_head\" in name)\n",
    "        ):\n",
    "            remote_names.append(name)\n",
    "\n",
    "        elif isinstance(module, CustomConv1D):\n",
    "            remote_names.append(name + \".forward_module\")\n",
    "            remote_names.append(name + \".backward_module\")\n",
    "\n",
    "    return remote_names\n",
    "\n",
    "\n",
    "# Do not include embedding layers as the model does not converge when quantizing them, even with\n",
    "# 16 bits\n",
    "remote_names = get_remote_names(lora_training, include_embedding_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = HybridFHEModel(lora_training, module_names=remote_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randint(0, 2, (PER_DEVICE_TRAIN_BATCH_SIZE, BLOCK_SIZE)) * (\n",
    "    tokenizer.vocab_size - 1\n",
    ")\n",
    "label_tensor = torch.randint(0, 2, (PER_DEVICE_TRAIN_BATCH_SIZE, BLOCK_SIZE)) * (\n",
    "    tokenizer.vocab_size - 1\n",
    ")\n",
    "\n",
    "inputset = (input_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.model.toggle_calibrate(enable=True)\n",
    "\n",
    "hybrid_model.compile_model(inputset, n_bits=16)\n",
    "\n",
    "hybrid_model.model.toggle_calibrate(enable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_model(hybrid_model, train_dataloader, training_args, fhe=\"disable\"):\n",
    "    device = \"cpu\"\n",
    "    hybrid_model.model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    hybrid_model.model.inference_model.train()\n",
    "\n",
    "    total_epochs = int(training_args.num_train_epochs)\n",
    "    epoch_pbar = tqdm(total=total_epochs, desc=\"Training Progress\", position=0)\n",
    "\n",
    "    total_batched_samples = 0\n",
    "    epoch_losses = []  # List to store the loss for each epoch\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        total_loss = 0\n",
    "        grad_norms = []\n",
    "\n",
    "        steps_in_epoch = len(train_dataloader)\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            total_batched_samples += 1\n",
    "\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Gradient accumulation\n",
    "            is_last_batch_step = (\n",
    "                steps_in_epoch <= training_args.gradient_accumulation_steps\n",
    "                and (step + 1) == steps_in_epoch  # noqa: W503\n",
    "            )\n",
    "            accumulate_gradients = (\n",
    "                total_batched_samples % training_args.gradient_accumulation_steps == 0\n",
    "            )\n",
    "\n",
    "            run_optimizer = is_last_batch_step or accumulate_gradients\n",
    "\n",
    "            hybrid_model.model.toggle_run_optimizer(enable=run_optimizer)\n",
    "\n",
    "            loss, grad_norm = hybrid_model((batch[\"input_ids\"], batch[\"labels\"]), fhe=fhe)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if grad_norm is not None:\n",
    "                grad_norms.append(grad_norm)\n",
    "\n",
    "        # Get current learning rate\n",
    "        current_lr = hybrid_model.model.lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "        # Get last grad norm\n",
    "        current_grad_norm = grad_norms[-1]\n",
    "\n",
    "        # Store the total loss for this epoch\n",
    "        epoch_losses.append(total_loss)\n",
    "\n",
    "        # Log epoch results\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{training_args.num_train_epochs}, \"\n",
    "            f\"Loss: {total_loss:.4f}, grad norm: {current_grad_norm}, lr: {current_lr}\"\n",
    "        )\n",
    "\n",
    "        epoch_pbar.update(1)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if training_args.output_dir is not None:\n",
    "        save_path = f\"{training_args.output_dir}/checkpoint-{epoch + 1}\"\n",
    "        hybrid_model.model.inference_model.save_pretrained(save_path)\n",
    "\n",
    "    epoch_pbar.close()\n",
    "\n",
    "    # Plot the loss evolution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, total_epochs + 1), epoch_losses, marker=\"o\")\n",
    "    plt.title(\"Loss Evolution During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Total Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Progress:   1%|          | 1/100 [04:21<7:11:59, 261.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.5474, grad norm: 0.3355550169944763, lr: 0.000495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [05:37<4:08:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 1.5155, grad norm: 0.31825020909309387, lr: 0.00049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [06:53<3:10:17, 117.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 1.5275, grad norm: 0.3436938226222992, lr: 0.00048499999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [08:11<2:42:54, 101.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 1.5121, grad norm: 0.4020688533782959, lr: 0.00048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [09:29<2:27:34, 93.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 1.4918, grad norm: 0.4025989770889282, lr: 0.000475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [10:46<2:17:27, 87.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 1.4430, grad norm: 0.45770904421806335, lr: 0.00047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [12:02<2:10:11, 84.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 1.4133, grad norm: 0.430878221988678, lr: 0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [13:19<2:05:08, 81.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Loss: 1.4292, grad norm: 0.41887837648391724, lr: 0.00046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [14:36<2:01:38, 80.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Loss: 1.3899, grad norm: 0.4334312081336975, lr: 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 10/100 [15:53<1:58:45, 79.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 1.3726, grad norm: 0.39489904046058655, lr: 0.00045000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 11/100 [17:10<1:56:41, 78.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Loss: 1.3595, grad norm: 0.4469723701477051, lr: 0.00044500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 12/100 [18:27<1:54:34, 78.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Loss: 1.3315, grad norm: 0.4357779920101166, lr: 0.00044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 13/100 [19:46<1:53:25, 78.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Loss: 1.3278, grad norm: 0.43598729372024536, lr: 0.000435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 14/100 [21:04<1:52:18, 78.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Loss: 1.2945, grad norm: 0.45333367586135864, lr: 0.00043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  15%|█▌        | 15/100 [22:25<1:52:00, 79.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Loss: 1.2902, grad norm: 0.6687149405479431, lr: 0.000425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 16/100 [23:43<1:50:10, 78.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Loss: 1.2780, grad norm: 0.6073557138442993, lr: 0.00042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 17/100 [25:01<1:48:45, 78.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Loss: 1.2283, grad norm: 0.4445655047893524, lr: 0.000415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 18/100 [26:20<1:47:31, 78.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Loss: 1.2346, grad norm: 0.45586520433425903, lr: 0.00041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  19%|█▉        | 19/100 [27:40<1:46:32, 78.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Loss: 1.2004, grad norm: 0.5274876952171326, lr: 0.00040500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 20/100 [28:58<1:44:54, 78.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 1.1746, grad norm: 0.4991244375705719, lr: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  21%|██        | 21/100 [30:17<1:43:43, 78.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Loss: 1.1872, grad norm: 0.6167137622833252, lr: 0.000395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 22/100 [31:34<1:41:51, 78.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Loss: 1.1244, grad norm: 0.4996899366378784, lr: 0.00039000000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  23%|██▎       | 23/100 [32:52<1:40:17, 78.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Loss: 1.1141, grad norm: 0.5516778826713562, lr: 0.00038500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|██▍       | 24/100 [34:10<1:38:58, 78.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Loss: 1.1002, grad norm: 0.602400541305542, lr: 0.00038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  25%|██▌       | 25/100 [35:27<1:37:18, 77.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Loss: 1.0972, grad norm: 0.550011932849884, lr: 0.000375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 26/100 [36:46<1:36:37, 78.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Loss: 1.0889, grad norm: 0.6990661025047302, lr: 0.00037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  27%|██▋       | 27/100 [38:05<1:35:29, 78.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Loss: 1.0476, grad norm: 0.6277032494544983, lr: 0.000365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  28%|██▊       | 28/100 [39:27<1:35:25, 79.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Loss: 1.0656, grad norm: 0.6060994267463684, lr: 0.00035999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  29%|██▉       | 29/100 [40:50<1:35:06, 80.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Loss: 1.0325, grad norm: 0.6185253262519836, lr: 0.000355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 30/100 [42:11<1:34:06, 80.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 1.0285, grad norm: 0.6253380179405212, lr: 0.00035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  31%|███       | 31/100 [43:33<1:33:06, 80.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Loss: 1.0221, grad norm: 0.7144878506660461, lr: 0.000345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 32/100 [44:55<1:32:06, 81.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Loss: 0.9745, grad norm: 0.6706973314285278, lr: 0.00034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  33%|███▎      | 33/100 [46:14<1:30:10, 80.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Loss: 0.9694, grad norm: 0.6786661744117737, lr: 0.000335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 34/100 [47:33<1:28:04, 80.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Loss: 0.9690, grad norm: 0.7508000731468201, lr: 0.00033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  35%|███▌      | 35/100 [48:53<1:26:41, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Loss: 0.9460, grad norm: 0.7483748197555542, lr: 0.00032500000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  36%|███▌      | 36/100 [50:13<1:25:34, 80.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Loss: 0.9379, grad norm: 0.6985185146331787, lr: 0.00032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  37%|███▋      | 37/100 [51:34<1:24:24, 80.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Loss: 0.9350, grad norm: 0.6791425943374634, lr: 0.000315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  38%|███▊      | 38/100 [52:53<1:22:45, 80.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Loss: 0.9112, grad norm: 0.7387422323226929, lr: 0.00031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  39%|███▉      | 39/100 [54:15<1:21:53, 80.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Loss: 0.9136, grad norm: 0.7416313290596008, lr: 0.000305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 40/100 [55:36<1:20:35, 80.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.8848, grad norm: 0.7500932216644287, lr: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  41%|████      | 41/100 [56:55<1:18:58, 80.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Loss: 0.8730, grad norm: 0.7485813498497009, lr: 0.000295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  42%|████▏     | 42/100 [58:18<1:18:15, 80.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Loss: 0.8654, grad norm: 0.8158472180366516, lr: 0.00029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  43%|████▎     | 43/100 [59:40<1:17:19, 81.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Loss: 0.8424, grad norm: 0.7175841331481934, lr: 0.000285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  44%|████▍     | 44/100 [1:01:00<1:15:33, 80.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Loss: 0.8444, grad norm: 0.7510058283805847, lr: 0.00028000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  45%|████▌     | 45/100 [1:02:22<1:14:28, 81.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Loss: 0.8358, grad norm: 0.8201435208320618, lr: 0.000275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  46%|████▌     | 46/100 [1:03:42<1:12:51, 80.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Loss: 0.8206, grad norm: 0.8101125955581665, lr: 0.00027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  47%|████▋     | 47/100 [1:05:04<1:11:47, 81.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Loss: 0.8212, grad norm: 0.857807993888855, lr: 0.00026500000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  48%|████▊     | 48/100 [1:06:24<1:10:04, 80.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Loss: 0.8047, grad norm: 0.8056545853614807, lr: 0.00026000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  49%|████▉     | 49/100 [1:07:46<1:08:56, 81.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Loss: 0.8022, grad norm: 0.9604797959327698, lr: 0.000255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 50/100 [1:09:09<1:08:08, 81.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.7991, grad norm: 0.8402461409568787, lr: 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  51%|█████     | 51/100 [1:10:32<1:06:58, 82.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Loss: 0.7707, grad norm: 0.8492586016654968, lr: 0.000245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  52%|█████▏    | 52/100 [1:11:54<1:05:33, 81.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Loss: 0.7424, grad norm: 0.8156391382217407, lr: 0.00024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  53%|█████▎    | 53/100 [1:13:15<1:04:07, 81.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Loss: 0.7495, grad norm: 0.8408838510513306, lr: 0.000235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  54%|█████▍    | 54/100 [1:14:38<1:02:49, 81.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Loss: 0.7483, grad norm: 0.8604503273963928, lr: 0.00023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  55%|█████▌    | 55/100 [1:15:59<1:01:19, 81.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Loss: 0.7442, grad norm: 0.8854144811630249, lr: 0.00022500000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  56%|█████▌    | 56/100 [1:17:22<1:00:18, 82.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Loss: 0.7407, grad norm: 0.8788455724716187, lr: 0.00022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  57%|█████▋    | 57/100 [1:18:42<58:30, 81.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Loss: 0.7387, grad norm: 0.8970968723297119, lr: 0.000215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  58%|█████▊    | 58/100 [1:20:05<57:19, 81.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Loss: 0.7260, grad norm: 0.8925109505653381, lr: 0.00021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  59%|█████▉    | 59/100 [1:21:26<55:53, 81.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Loss: 0.6772, grad norm: 0.9218511581420898, lr: 0.000205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 60/100 [1:22:50<54:55, 82.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.6988, grad norm: 0.9442291259765625, lr: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  61%|██████    | 61/100 [1:24:14<53:54, 82.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Loss: 0.7092, grad norm: 0.9974638223648071, lr: 0.00019500000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  62%|██████▏   | 62/100 [1:25:50<54:52, 86.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Loss: 0.6930, grad norm: 1.0726863145828247, lr: 0.00019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  63%|██████▎   | 63/100 [1:27:22<54:24, 88.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Loss: 0.6756, grad norm: 1.0581772327423096, lr: 0.000185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  64%|██████▍   | 64/100 [1:28:42<51:26, 85.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Loss: 0.6719, grad norm: 0.9272902607917786, lr: 0.00017999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  65%|██████▌   | 65/100 [1:30:01<48:52, 83.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Loss: 0.6711, grad norm: 1.0115615129470825, lr: 0.000175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  66%|██████▌   | 66/100 [1:31:20<46:39, 82.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Loss: 0.6454, grad norm: 1.0066094398498535, lr: 0.00017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  67%|██████▋   | 67/100 [1:32:39<44:45, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Loss: 0.6618, grad norm: 1.120772123336792, lr: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  68%|██████▊   | 68/100 [1:33:58<43:00, 80.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Loss: 0.6186, grad norm: 0.9725711941719055, lr: 0.00016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  69%|██████▉   | 69/100 [1:35:17<41:27, 80.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Loss: 0.6370, grad norm: 1.082191824913025, lr: 0.000155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 70/100 [1:36:36<39:55, 79.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.6318, grad norm: 0.9971476197242737, lr: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  71%|███████   | 71/100 [1:37:55<38:26, 79.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Loss: 0.6331, grad norm: 0.963691771030426, lr: 0.000145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  72%|███████▏  | 72/100 [1:39:15<37:11, 79.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Loss: 0.6309, grad norm: 1.3207135200500488, lr: 0.00014000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  73%|███████▎  | 73/100 [1:40:35<35:54, 79.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Loss: 0.6136, grad norm: 1.0440832376480103, lr: 0.000135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  74%|███████▍  | 74/100 [1:41:56<34:43, 80.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Loss: 0.6104, grad norm: 0.9647199511528015, lr: 0.00013000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  75%|███████▌  | 75/100 [1:43:17<33:27, 80.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Loss: 0.5994, grad norm: 1.0407522916793823, lr: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  76%|███████▌  | 76/100 [1:44:37<32:04, 80.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Loss: 0.6159, grad norm: 1.2311997413635254, lr: 0.00012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  77%|███████▋  | 77/100 [1:45:56<30:37, 79.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Loss: 0.5741, grad norm: 1.0105656385421753, lr: 0.000115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  78%|███████▊  | 78/100 [1:47:15<29:11, 79.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Loss: 0.5841, grad norm: 1.1994893550872803, lr: 0.00011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  79%|███████▉  | 79/100 [1:48:34<27:51, 79.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Loss: 0.6114, grad norm: 1.0626143217086792, lr: 0.000105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 80/100 [1:49:54<26:35, 79.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.5880, grad norm: 1.054750919342041, lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  81%|████████  | 81/100 [1:51:14<25:16, 79.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Loss: 0.5655, grad norm: 0.9550267457962036, lr: 9.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  82%|████████▏ | 82/100 [1:52:35<24:03, 80.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Loss: 0.5946, grad norm: 1.1578212976455688, lr: 8.999999999999999e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  83%|████████▎ | 83/100 [1:53:55<22:41, 80.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Loss: 0.6003, grad norm: 1.075507640838623, lr: 8.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  84%|████████▍ | 84/100 [1:55:15<21:21, 80.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Loss: 0.5775, grad norm: 1.0394887924194336, lr: 8e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  85%|████████▌ | 85/100 [1:56:34<19:56, 79.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Loss: 0.5864, grad norm: 1.0302282571792603, lr: 7.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  86%|████████▌ | 86/100 [1:57:54<18:34, 79.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Loss: 0.5628, grad norm: 1.1795330047607422, lr: 7.000000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  87%|████████▋ | 87/100 [1:59:13<17:14, 79.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Loss: 0.5564, grad norm: 1.086024284362793, lr: 6.500000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  88%|████████▊ | 88/100 [2:00:33<15:56, 79.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Loss: 0.5744, grad norm: 1.257170557975769, lr: 6e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  89%|████████▉ | 89/100 [2:01:52<14:34, 79.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Loss: 0.5486, grad norm: 1.1120915412902832, lr: 5.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 90/100 [2:03:12<13:15, 79.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.5657, grad norm: 1.0620477199554443, lr: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  91%|█████████ | 91/100 [2:04:32<11:57, 79.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Loss: 0.5395, grad norm: 1.2674777507781982, lr: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  92%|█████████▏| 92/100 [2:05:52<10:39, 79.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Loss: 0.5680, grad norm: 1.1475542783737183, lr: 4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  93%|█████████▎| 93/100 [2:07:13<09:21, 80.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Loss: 0.5806, grad norm: 1.1923059225082397, lr: 3.5000000000000004e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  94%|█████████▍| 94/100 [2:08:44<08:20, 83.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Loss: 0.5429, grad norm: 0.9368011951446533, lr: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  95%|█████████▌| 95/100 [2:10:20<07:15, 87.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Loss: 0.5607, grad norm: 1.0647990703582764, lr: 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  96%|█████████▌| 96/100 [2:11:46<05:46, 86.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Loss: 0.5430, grad norm: 1.1920421123504639, lr: 2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  97%|█████████▋| 97/100 [2:13:05<04:13, 84.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Loss: 0.5526, grad norm: 0.9896294474601746, lr: 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  98%|█████████▊| 98/100 [2:14:25<02:46, 83.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Loss: 0.5591, grad norm: 1.126670241355896, lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  99%|█████████▉| 99/100 [2:15:45<01:22, 82.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Loss: 0.5530, grad norm: 1.1123902797698975, lr: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [2:17:06<00:00, 81.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.5362, grad norm: 1.0141682624816895, lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [2:17:07<00:00, 82.28s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avoid the following error from HuggingFace when training :\n",
    "# \"The current process just got forked, after parallelism has already been used. Disabling\n",
    "# parallelism to avoid deadlocks...\"\n",
    "tokenizer.parallelism = False\n",
    "\n",
    "train_custom_model(hybrid_model, train_dataloader, training_args, fhe=\"simulate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = hybrid_model.model.inference_model\n",
    "\n",
    "# In simulation, we can only generate a single token at a time because of fixed size circuits\n",
    "# and how `generate` works (only the last token from the previous generation is kept)\n",
    "hybrid_model.set_fhe_mode(\"disable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is FHE?\n",
      "\n",
      "FHE? FHS is a groundbreaking concept that allows the use of cloud computing to help protect data and privacy while still allowing data to be\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is FHE ?\"\n",
    "generated_text = generate_text(prompt, fine_tuned_model, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is FHE?\n",
      "\n",
      "FHE is a new form of the term \"fission energy\". It is the energy of fusion of a process which is in a state\n"
     ]
    }
   ],
   "source": [
    "peft_model.disable_adapter_layers()\n",
    "\n",
    "prompt = \"What is FHE ?\"\n",
    "generated_text = generate_text(prompt, fine_tuned_model, tokenizer)\n",
    "print(generated_text)\n",
    "\n",
    "peft_model.enable_adapter_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights_and_size(model, print_detail=False):\n",
    "    total_weights = 0\n",
    "    total_lora_weights = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        total_weights += param.numel()\n",
    "\n",
    "        if \"lora\" in name:\n",
    "            total_lora_weights += param.numel()\n",
    "\n",
    "        if print_detail:\n",
    "            print(name, param.numel())\n",
    "\n",
    "    print(f\"Total number of weights: {total_weights}\")\n",
    "    print(f\"Total number of LoRA weights: {total_lora_weights}\")\n",
    "\n",
    "    return total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights: 124587264\n",
      "Total number of LoRA weights: 147456\n"
     ]
    }
   ],
   "source": [
    "total_weights_size = print_weights_and_size(hybrid_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"deployment/gpt2_lora_finetuned\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if path.is_dir() and any(path.iterdir()):\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "hybrid_model.save_and_clear_private_info(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights: 39569664\n",
      "Total number of LoRA weights: 147456\n"
     ]
    }
   ],
   "source": [
    "total_weights_size_private = print_weights_and_size(hybrid_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights removed: 68.24 %\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Total weights removed: \"\n",
    "    f\"{(total_weights_size - total_weights_size_private) / total_weights_size * 100:.2f} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 95% of the remaining weights are from the embedding layers (wpe and wte) as well as the final lm_head layer."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
