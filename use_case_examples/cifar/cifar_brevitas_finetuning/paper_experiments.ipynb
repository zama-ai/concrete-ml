{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import time\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "import os\n",
    "import brevitas\n",
    "import brevitas.nn as qnn\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from brevitas import config\n",
    "from brevitas.quant import Int8ActPerTensorFloat, Int8WeightPerTensorFloat\n",
    "from concrete.fhe.compilation import Configuration\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concrete.fhe import Exactness\n",
    "from concrete.ml.torch.compile import compile_brevitas_qat_model, compile_torch_model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "from cifar_utils import (\n",
    "    fhe_compatibility,\n",
    "    get_dataloader,\n",
    "    mapping_keys,\n",
    "    plot_baseline,\n",
    "    plot_dataset,\n",
    "    torch_inference,\n",
    "    train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!> Since MNIST is a relatively simple task, training a floating-point model and then fine-tuning the quantized model yields the same results as training the quantized model from scratch.\n",
    "\n",
    "- If we train first the FP32, then assign the weights to the Brevitas model, and finally finetune it, we save like  10 epochs \n",
    "\n",
    "<!> That's why the following cell is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMG_SIZE = 28\n",
    "\n",
    "FEATURES_MAPS = [\n",
    "    (\"I\",),\n",
    "    # Padding tuple (left, right, top, bottom), mode \n",
    "    # (\"P\", (1, 1, 1, 1), 'replicate'),   \n",
    "    # (\"I\",),  \n",
    "    # Layer 1: INPUT_IMG_SIZE, out_size, kernel_size=t[3], stride=t[4], padding=t[5], padding_mode=\"replicate\")\n",
    "    (\"C\", 1, 1, 3, 0, 1, \"replicate\"),\n",
    "]\n",
    "\n",
    "\n",
    "# In the paper, we have 17 identity layers (frozen layers)\n",
    "LINEAR_LAYERS = lambda nb_layers: (\n",
    "    [(\"R\",), (\"L\", INPUT_IMG_SIZE * INPUT_IMG_SIZE, 92),  (\"I\",), (\"B\", 92), (\"I\",),] + \\\n",
    "    [(\"R\",), (\"L\", 92, 92),  (\"I\",), (\"B\", 92), (\"I\",),] * (nb_layers - 2) + [(\"L\", 92, 10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicatePad2d(nn.Module):\n",
    "    def __init__(self, padding, mode):\n",
    "        super(ReplicatePad2d, self).__init__()\n",
    "        self.padding = padding  # padding is expected as a tuple (left, right, top, bottom)\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.pad(x, self.padding, mode=self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fp32MNIST(nn.Module):\n",
    "    def __init__(self, output_size: int, nb_layers: int):\n",
    "        super(Fp32MNIST, self).__init__()\n",
    "        \"\"\" Torch model.\n",
    "\n",
    "        Args:\n",
    "            output_size (int): Number of classes.\n",
    "        \"\"\"\n",
    "        self.output_size = output_size\n",
    "        self.nb_layers = nb_layers\n",
    "\n",
    "        def make_layers(t):\n",
    "\n",
    "            if t[0] == \"P\":\n",
    "                return ReplicatePad2d(t[1], t[2])\n",
    "            elif t[0] == \"C\":\n",
    "                return nn.Conv2d(1, 1, kernel_size=3, stride=1)\n",
    "            elif t[0] == \"L\":\n",
    "                return nn.Linear(in_features=t[1], out_features=t[2])\n",
    "            elif t[0] == \"R\":\n",
    "                return nn.ReLU()\n",
    "            elif t[0] == \"F\":\n",
    "                return nn.Flatten(1, -1)\n",
    "            elif t[0]:\n",
    "                return nn.BatchNorm1d(t[1])\n",
    "            else:\n",
    "                raise NameError(f\"{t} not defined\")\n",
    "\n",
    "        self.features_maps = nn.Sequential(*[make_layers(t) for t in FEATURES_MAPS if t[0] != \"I\"])\n",
    "        self.linears = nn.Sequential(*[make_layers(t) for t in LINEAR_LAYERS(self.nb_layers) if t[0] != \"I\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_maps(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.linears(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantMNIST(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bit: int,\n",
    "        output_size: int = 10,\n",
    "        nb_layers: int = 20, \n",
    "        act_quant: brevitas.quant = Int8ActPerTensorFloat,\n",
    "        weight_quant: brevitas.quant = Int8WeightPerTensorFloat,\n",
    "    ):\n",
    "        \"\"\"A quantized network with Brevitas.\n",
    "\n",
    "        Args:\n",
    "            bit (int): Bit of quantization.\n",
    "            output_size (int): Number of classes.\n",
    "            act_quant (brevitas.quant): Quantization protocol of activations.\n",
    "            weight_quant (brevitas.quant): Quantization protocol of the weights.\n",
    "\n",
    "        \"\"\"\n",
    "        super(QuantMNIST, self).__init__()\n",
    "        self.bit = bit\n",
    "        self.nb_layers = nb_layers\n",
    "\n",
    "        def tuple2quantlayer(t):\n",
    "            if t[0] == \"P\":\n",
    "                return ReplicatePad2d(t[1], t[2])\n",
    "            if t[0] == \"R\":\n",
    "                return qnn.QuantReLU(return_quant_tensor=True, bit_width=bit, act_quant=act_quant)\n",
    "            if t[0] == \"C\":\n",
    "                return qnn.QuantConv2d(\n",
    "                    t[1],\n",
    "                    t[2],\n",
    "                    kernel_size=t[3],\n",
    "                    # stride=t[4],\n",
    "                    weight_bit_width=2,\n",
    "                    weight_quant=weight_quant,\n",
    "                    return_quant_tensor=True,\n",
    "                )\n",
    "            if t[0] == \"L\":\n",
    "                return qnn.QuantLinear(\n",
    "                    in_features=t[1],\n",
    "                    out_features=t[2],\n",
    "                    weight_bit_width=bit,\n",
    "                    weight_quant=weight_quant,\n",
    "                    bias=True,\n",
    "                    return_quant_tensor=True,\n",
    "                )\n",
    "            if t[0] == \"I\":\n",
    "                identity_quant = t[1] if len(t) == 2 else bit\n",
    "                return qnn.QuantIdentity(\n",
    "                    bit_width=identity_quant, act_quant=act_quant, return_quant_tensor=True\n",
    "                )\n",
    "            if t[0] == \"B\":\n",
    "                return nn.BatchNorm1d(t[1])\n",
    "\n",
    "        self.features_maps = nn.Sequential(\n",
    "            *[tuple2quantlayer(t) for t in FEATURES_MAPS if t[0] != \"I\"]\n",
    "        )\n",
    "\n",
    "        # self.identity1 and self.identity2 are used to encapsulate the `torch.flatten`.\n",
    "        self.identity1 = qnn.QuantIdentity(\n",
    "            bit_width=bit, act_quant=act_quant, return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "        self.identity2 = qnn.QuantIdentity(\n",
    "            bit_width=bit, act_quant=act_quant, return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "        self.linears = nn.Sequential(*[tuple2quantlayer(t) for t in LINEAR_LAYERS(self.nb_layers) if t[0] != \"I\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_maps(x)\n",
    "        x = self.identity1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.identity2(x)\n",
    "        x = self.linears(x)\n",
    "        return x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fp32_model, quant_model, compile_type, data_calibration, data_loader, bits=None):\n",
    "\n",
    "    bits = quant_model.bit if compile_type == \"qat\" else bits\n",
    "    model = quant_model if compile_type == \"qat\" else fp32_model \n",
    "    nb_layers = quant_model.nb_layers\n",
    "    compile_function = compile_brevitas_qat_model if compile_type == \"qat\" else compile_torch_model\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"{nb_layers=}, {bits=}, {compile_type=}, {compile_function=}\")\n",
    "\n",
    "    history = []\n",
    "\n",
    "    filename = f\"history_{nb_layers=}_v2.csv\"\n",
    "    headers = [\"Compile_Type\", \"Number_of_Layers\", \"Bits\", \"Threshold\", \"Max_Bits\",\n",
    "               \"Mean_FP32_Accuracy\", \"Mean_Disable_Accuracy\", \"Mean_Simulate_Accuracy\", \"FHE_Timing\"]\n",
    "\n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"NEW FILE\")\n",
    "        with open(filename, \"w\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(headers)\n",
    "\n",
    "    with open(filename, \"a\", newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for j, threshold in tqdm(enumerate([7, 6, 5, 4, Exactness.APPROXIMATE, Exactness.EXACT])):\n",
    "\n",
    "            history_fp32_predictions = [] \n",
    "            history_disable_predictions = [] \n",
    "            history_simulat_predictions = [] \n",
    "            fhe_timing = 0\n",
    "\n",
    "            if 4: \n",
    "                key = f\"{compile_type} | layers={nb_layers} | {bits=} | {threshold=}\"\n",
    "                q_module = compile_function(\n",
    "                    model.to(\"cpu\"),\n",
    "                    torch_inputset=data_calibration,\n",
    "                    n_bits=None if compile_type == \"qat\" else bits,\n",
    "                    rounding_threshold_bits=threshold,\n",
    "                )\n",
    "\n",
    "                max_bits = q_module.fhe_circuit.graph.maximum_integer_bit_width()\n",
    "                print(f\"{j=}: {max_bits=}\")\n",
    "\n",
    "                for i, (data, labels) in tqdm(enumerate(data_loader)):\n",
    "                    \n",
    "                    fp32_predictions = model(data).cpu().detach()\n",
    "                    history_fp32_predictions.extend(fp32_predictions.argmax(1) == labels)\n",
    "                    \n",
    "                    data, labels = data.detach().cpu().numpy(), labels.detach().cpu().numpy()\n",
    "\n",
    "                    disable_predictions = q_module.forward(data, fhe=\"disable\")\n",
    "                    history_disable_predictions.extend(disable_predictions.argmax(1) == labels)\n",
    "\n",
    "                    simulat_predictions = q_module.forward(data, fhe=\"simulate\")\n",
    "                    history_simulat_predictions.extend(simulat_predictions.argmax(1) == labels)\n",
    "\n",
    "                    if i == 0:\n",
    "                        start_time = time.time()\n",
    "                        q_module.forward(data[0, None], fhe=\"execute\")\n",
    "                        fhe_timing = ((time.time() - start_time) / 60.0)\n",
    "\n",
    "                row = [\n",
    "                    compile_type,\n",
    "                    nb_layers,\n",
    "                    bits,\n",
    "                    threshold,\n",
    "                    max_bits,\n",
    "                    np.mean(history_fp32_predictions),\n",
    "                    np.mean(history_disable_predictions),\n",
    "                    np.mean(history_simulat_predictions),\n",
    "                    fhe_timing\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                row = [compile_type, nb_layers, bits, threshold, -1, -1, -1, -1, -1]\n",
    "\n",
    "            writer.writerow(row)\n",
    "            print(f\"{j=}: {row=}\")\n",
    "            history.append(dict(zip(headers, row)))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 30, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  \"cpu\"\n",
    "\n",
    "param = {\n",
    "    \"output_size\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"dataset_name\": \"MNIST\",\n",
    "    \"dataset\": datasets.MNIST,\n",
    "    \"training\": \"fp32\",\n",
    "    \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "    \"accuracy_test\": [],\n",
    "    \"accuracy_train\": [],\n",
    "    \"loss_test_history\": [],\n",
    "    \"loss_train_history\": [],\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "train_loader, test_loader = get_dataloader(param=param)\n",
    "\n",
    "data_calibration = next(iter(train_loader))[0]\n",
    "\n",
    "plot_dataset(test_loader, param)\n",
    "\n",
    "data_calibration.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP32 MNIST 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layers = 20\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\",\n",
    "\n",
    "fp32_mnist_20 = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: Train loss = 0.6650 VS Test loss = 0.5419 - Accuracy train: 0.7971 VS Accuracy test: 0.8859\n",
      "Epoch  1: Train loss = 0.3863 VS Test loss = 0.3187 - Accuracy train: 0.9059 VS Accuracy test: 0.9206\n",
      "Epoch  2: Train loss = 0.2996 VS Test loss = 0.4548 - Accuracy train: 0.9283 VS Accuracy test: 0.9050\n",
      "Epoch  3: Train loss = 0.2683 VS Test loss = 0.5307 - Accuracy train: 0.9369 VS Accuracy test: 0.8632\n",
      "Epoch  4: Train loss = 0.2703 VS Test loss = 0.2626 - Accuracy train: 0.9358 VS Accuracy test: 0.9562\n",
      "Epoch  5: Train loss = 0.2228 VS Test loss = 0.2361 - Accuracy train: 0.9484 VS Accuracy test: 0.9625\n",
      "Epoch  6: Train loss = 0.2047 VS Test loss = 0.2350 - Accuracy train: 0.9521 VS Accuracy test: 0.9642\n",
      "Epoch  7: Train loss = 0.2016 VS Test loss = 0.1999 - Accuracy train: 0.9522 VS Accuracy test: 0.9585\n",
      "Epoch  8: Train loss = 0.1762 VS Test loss = 0.1687 - Accuracy train: 0.9576 VS Accuracy test: 0.9690\n",
      "Epoch  9: Train loss = 0.1819 VS Test loss = 0.1779 - Accuracy train: 0.9567 VS Accuracy test: 0.9618\n",
      "Epoch 10: Train loss = 0.1603 VS Test loss = 0.1711 - Accuracy train: 0.9607 VS Accuracy test: 0.9634\n",
      "Epoch 11: Train loss = 0.1444 VS Test loss = 0.1570 - Accuracy train: 0.9654 VS Accuracy test: 0.9751\n",
      "Epoch 12: Train loss = 0.1374 VS Test loss = 0.1525 - Accuracy train: 0.9667 VS Accuracy test: 0.9706\n",
      "Epoch 13: Train loss = 0.1307 VS Test loss = 0.1625 - Accuracy train: 0.9674 VS Accuracy test: 0.9712\n",
      "Epoch 14: Train loss = 0.1126 VS Test loss = 0.1189 - Accuracy train: 0.9720 VS Accuracy test: 0.9758\n",
      "Epoch 15: Train loss = 0.0761 VS Test loss = 0.1047 - Accuracy train: 0.9806 VS Accuracy test: 0.9799\n",
      "Epoch 16: Train loss = 0.0645 VS Test loss = 0.1127 - Accuracy train: 0.9833 VS Accuracy test: 0.9797\n",
      "Epoch 17: Train loss = 0.0575 VS Test loss = 0.1138 - Accuracy train: 0.9848 VS Accuracy test: 0.9806\n",
      "Epoch 18: Train loss = 0.0541 VS Test loss = 0.0957 - Accuracy train: 0.9863 VS Accuracy test: 0.9811\n",
      "Epoch 19: Train loss = 0.0500 VS Test loss = 0.0959 - Accuracy train: 0.9867 VS Accuracy test: 0.9821\n",
      "Epoch 20: Train loss = 0.0510 VS Test loss = 0.0849 - Accuracy train: 0.9865 VS Accuracy test: 0.9824\n",
      "Epoch 21: Train loss = 0.0480 VS Test loss = 0.0857 - Accuracy train: 0.9873 VS Accuracy test: 0.9814\n",
      "Epoch 22: Train loss = 0.0479 VS Test loss = 0.0977 - Accuracy train: 0.9870 VS Accuracy test: 0.9797\n",
      "Epoch 23: Train loss = 0.0442 VS Test loss = 0.0863 - Accuracy train: 0.9882 VS Accuracy test: 0.9801\n",
      "Epoch 24: Train loss = 0.0399 VS Test loss = 0.0830 - Accuracy train: 0.9893 VS Accuracy test: 0.9799\n",
      "Epoch 25: Train loss = 0.0392 VS Test loss = 0.0830 - Accuracy train: 0.9893 VS Accuracy test: 0.9810\n",
      "Epoch 26: Train loss = 0.0400 VS Test loss = 0.0829 - Accuracy train: 0.9894 VS Accuracy test: 0.9816\n",
      "Epoch 27: Train loss = 0.0395 VS Test loss = 0.0834 - Accuracy train: 0.9891 VS Accuracy test: 0.9818\n",
      "Epoch 28: Train loss = 0.0384 VS Test loss = 0.0771 - Accuracy train: 0.9900 VS Accuracy test: 0.9815\n",
      "Epoch 29: Train loss = 0.0391 VS Test loss = 0.0837 - Accuracy train: 0.9891 VS Accuracy test: 0.9814\n",
      "100%|| 30/30 [27:21<00:00, 54.72s/it]\n"
     ]
    }
   ],
   "source": [
    "run = False\n",
    "\n",
    "if run:\n",
    "    param[\"training\"] = \"fp32\"\n",
    "    param[\"epochs\"] = 30\n",
    "    param[\"lr\"] = 0.01\n",
    "    param[\"milestones\"] = [15, 24]\n",
    "    param[\"gamma\"] = 0.1\n",
    "\n",
    "    fp32_mnist = train(fp32_mnist_20, train_loader, test_loader, param, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20-nb_layers: acc_after_ft_train=99.310% vs acc_after_ft_test=98.137%\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "checkpoint = torch.load(f\"checkpoints/MNIST/NLP_{nb_layers}/fp32/MNIST_fp32_state_dict.pt\", map_location=device)\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "\n",
    "fp32_mnist.load_state_dict(checkpoint)\n",
    "\n",
    "acc_after_ft_train = torch_inference(fp32_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(fp32_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {fp32_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quant MNIST 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bits, run, nb_layers = 3, False, 20\n",
    "\n",
    "# quant_mnist = QuantMNIST(bit=bits, output_size=param[\"output_size\"], nb_layers=nb_layers).to(\"cpu\")\n",
    "# quant_mnist = mapping_keys(checkpoint, quant_mnist, device=\"cpu\")\n",
    "# acc_before_ft = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "# print(f\"Accuracy before fine-tuning: {acc_before_ft=:.3%}\")\n",
    "# qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "# print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")\n",
    "\n",
    "# # if run:\n",
    "# #     param[\"training\"] = f\"quant_mnist_{bits=}\"\n",
    "# #     param[\"epochs\"] = 9\n",
    "# #     param[\"lr\"] = 0.1\n",
    "# #     param[\"milestones\"] = [3]\n",
    "# #     param[\"gamma\"] = 0.1\n",
    "# #     quant_mnist = train(quant_mnist, train_loader, test_loader, param, device=device)\n",
    "\n",
    "# path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "\n",
    "# quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "# quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "# acc_after_ft_train = torch_inference(quant_mnist, train_loader, device=device)\n",
    "# acc_after_ft_test  = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "# print(\n",
    "#     f\"With {quant_mnist.bit}-bits and {quant_mnist.nb_layers}-nb_layers: \"\n",
    "#     f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "#     )\n",
    "\n",
    "# qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "# print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before fine-tuning: acc_before_ft=9.746%\n",
      "Maximum bit-width in the circuit: 13\n",
      "\n",
      "With 4-bits and 20-nb_layers: acc_after_ft_train=97.322% vs acc_after_ft_test=97.165%\n",
      "Maximum bit-width in the circuit: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bits, run, nb_layers = 4, False, 20\n",
    "\n",
    "quant_mnist = QuantMNIST(bit=bits, output_size=param[\"output_size\"], nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist = mapping_keys(checkpoint, quant_mnist, device=\"cpu\")\n",
    "acc_before_ft = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "print(f\"Accuracy before fine-tuning: {acc_before_ft=:.3%}\")\n",
    "qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")\n",
    "\n",
    "# if run:\n",
    "#     param[\"training\"] = f\"quant_mnist_{bits=}\"\n",
    "#     param[\"epochs\"] = 5\n",
    "#     param[\"lr\"] = 0.1\n",
    "#     param[\"milestones\"] = [1, 3]\n",
    "#     param[\"gamma\"] = 0.1\n",
    "\n",
    "#     quant_mnist_20 = train(quant_mnist_20, train_loader, test_loader, param, device=device)\n",
    "\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "acc_after_ft_train = torch_inference(quant_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {quant_mnist.bit}-bits and {quant_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )\n",
    "\n",
    "qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 5\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "acc_after_ft_train = torch_inference(quant_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {quant_mnist.bit}-bits and {quant_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )\n",
    "\n",
    "qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run mnist nlp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bits = 4\n",
    "nb_layers = 20\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "checkpoint = torch.load(f\"checkpoints/MNIST/NLP_{nb_layers}/fp32/MNIST_fp32_state_dict.pt\", map_location=device)\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "fp32_mnist.load_state_dict(checkpoint)\n",
    "\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "history = run(fp32_mnist, quant_mnist, 'ptq', data_calibration, test_loader, bits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compile_Type</th>\n",
       "      <th>Number_of_Layers</th>\n",
       "      <th>Bits</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Max_Bits</th>\n",
       "      <th>Mean_FP32_Accuracy</th>\n",
       "      <th>Mean_Quant_Accuracy</th>\n",
       "      <th>FHE_Timing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>4.896937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.280711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>6.051062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>3.803362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>2.765119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>2.473194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>14</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.320772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>14</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>2.487677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>6.450424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.260818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>1.498341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>1.387384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>7.379651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>3.075301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.413206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>1.767676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qat</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>6.475842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>3.675923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>2.267627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>2.193188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>14</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>2.478869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>2.806964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.617310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.869187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.702622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Exactness.EXACT</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ptq</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Exactness.APPROXIMATE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.964811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compile_Type  Number_of_Layers  Bits              Threshold  Max_Bits  \\\n",
       "0           ptq                20     4                      7        13   \n",
       "1           ptq                20     4                      6        11   \n",
       "2           ptq                20     4                      4        -1   \n",
       "3           ptq                20     4        Exactness.EXACT        -1   \n",
       "4           ptq                20     4  Exactness.APPROXIMATE        -1   \n",
       "5           ptq                20     3        Exactness.EXACT        -1   \n",
       "6           ptq                20     3  Exactness.APPROXIMATE        -1   \n",
       "7           ptq                20     5        Exactness.EXACT        -1   \n",
       "8           ptq                20     5  Exactness.APPROXIMATE        -1   \n",
       "9           ptq                20     5                      7        15   \n",
       "10          ptq                20     5                      6        15   \n",
       "11          ptq                20     5                      5        15   \n",
       "12          ptq                20     5                      4        15   \n",
       "13          ptq                20     5        Exactness.EXACT        14   \n",
       "14          ptq                20     5  Exactness.APPROXIMATE        14   \n",
       "15          qat                20     4                      7        14   \n",
       "16          qat                20     4                      6        14   \n",
       "17          qat                20     4                      5        14   \n",
       "18          qat                20     4                      4        13   \n",
       "19          qat                20     4        Exactness.EXACT        -1   \n",
       "20          qat                20     4  Exactness.APPROXIMATE        -1   \n",
       "21          qat                20     5                      7        16   \n",
       "22          qat                20     5                      6        16   \n",
       "23          qat                20     5                      5        16   \n",
       "24          qat                20     5                      4        16   \n",
       "25          qat                20     5        Exactness.EXACT        -1   \n",
       "26          qat                20     5  Exactness.APPROXIMATE        -1   \n",
       "27          ptq                20     5                      7        13   \n",
       "28          ptq                20     5                      6        13   \n",
       "29          ptq                20     5                      5        13   \n",
       "30          ptq                20     5                      4        13   \n",
       "31          ptq                20     5        Exactness.EXACT        -1   \n",
       "32          ptq                20     5  Exactness.APPROXIMATE        14   \n",
       "33          ptq                20     3                      7         9   \n",
       "34          ptq                20     3                      6         9   \n",
       "35          ptq                20     3                      5         9   \n",
       "36          ptq                20     3                      4         9   \n",
       "37          ptq                20     3        Exactness.EXACT        -1   \n",
       "38          ptq                20     3  Exactness.APPROXIMATE        10   \n",
       "\n",
       "    Mean_FP32_Accuracy  Mean_Quant_Accuracy  FHE_Timing  \n",
       "0             0.093750             0.093750    4.896937  \n",
       "1             0.125000             0.125000    2.280711  \n",
       "2            -1.000000            -1.000000   -1.000000  \n",
       "3            -1.000000            -1.000000   -1.000000  \n",
       "4            -1.000000            -1.000000   -1.000000  \n",
       "5            -1.000000            -1.000000   -1.000000  \n",
       "6            -1.000000            -1.000000   -1.000000  \n",
       "7            -1.000000            -1.000000   -1.000000  \n",
       "8            -1.000000            -1.000000   -1.000000  \n",
       "9             0.093750             0.093750    6.051062  \n",
       "10            0.109375             0.109375    3.803362  \n",
       "11            0.046875             0.046875    2.765119  \n",
       "12            0.093750             0.093750    2.473194  \n",
       "13            0.125000             0.125000    2.320772  \n",
       "14            0.140625             0.140625    2.487677  \n",
       "15            0.984375             0.984375    6.450424  \n",
       "16            0.937500             0.937500    2.260818  \n",
       "17            0.890625             0.890625    1.498341  \n",
       "18            0.828125             0.828125    1.387384  \n",
       "19           -1.000000            -1.000000   -1.000000  \n",
       "20           -1.000000            -1.000000   -1.000000  \n",
       "21            0.906250             0.906250    7.379651  \n",
       "22            0.984375             0.984375    3.075301  \n",
       "23            0.937500             0.937500    2.413206  \n",
       "24            0.515625             0.421875    1.767676  \n",
       "25           -1.000000            -1.000000   -1.000000  \n",
       "26           -1.000000            -1.000000   -1.000000  \n",
       "27            0.093750             0.093750    6.475842  \n",
       "28            0.046875             0.046875    3.675923  \n",
       "29            0.078125             0.078125    2.267627  \n",
       "30            0.031250             0.031250    2.193188  \n",
       "31           -1.000000            -1.000000   -1.000000  \n",
       "32            0.015625             0.015625    2.478869  \n",
       "33            0.078125             0.062500    2.806964  \n",
       "34            0.109375             0.093750    1.617310  \n",
       "35            0.093750             0.093750    0.869187  \n",
       "36            0.046875             0.046875    0.702622  \n",
       "37           -1.000000            -1.000000   -1.000000  \n",
       "38            0.156250             0.156250    0.964811  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"history_nb_layers=20.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_layers=20, bits=4, compile_type='qat', compile_function=<function compile_brevitas_qat_model at 0x7f049a7496c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: max_bits=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [09:08,  3.52s/it]\n",
      "1it [09:14, 554.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: row=['qat', 20, 4, 7, 14, 0.984375, 0.984375, 6.450424118836721]\n",
      "j=1: max_bits=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:58,  1.91s/it]\n",
      "2it [14:19, 407.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1: row=['qat', 20, 4, 6, 14, 0.9375, 0.9375, 2.2608179012934366]\n",
      "j=2: max_bits=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:11,  1.61s/it]\n",
      "3it [18:36, 338.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=2: row=['qat', 20, 4, 5, 14, 0.890625, 0.890625, 1.4983412265777587]\n",
      "j=3: max_bits=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:04,  1.57s/it]\n",
      "4it [22:46, 303.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=3: row=['qat', 20, 4, 4, 13, 0.828125, 0.828125, 1.3873843431472779]\n",
      "x.bit_width=10 > lsbs_to_remove=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [22:50, 195.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=4: row=['qat', 20, 4, <Exactness.EXACT: 0>, -1, -1, -1, -1, -1]\n",
      "x.bit_width=11 > lsbs_to_remove=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [22:54, 229.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5: row=['qat', 20, 4, <Exactness.APPROXIMATE: 1>, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = run(fp32_mnist, quant_mnist, 'qat', data_calibration, test_loader, bits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_layers=20, bits=5, compile_type='ptq', compile_function=<function compile_torch_model at 0x7f049a7495a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: max_bits=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [08:47,  3.38s/it]\n",
      "1it [08:51, 531.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: row=['ptq', 20, 5, 7, 13, 0.09375, 0.09375, 6.47584156592687]\n",
      "j=1: max_bits=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [05:57,  2.29s/it]\n",
      "2it [14:54, 432.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1: row=['ptq', 20, 5, 6, 13, 0.046875, 0.046875, 3.6759230732917785]\n",
      "j=2: max_bits=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:33,  1.75s/it]\n",
      "3it [19:31, 361.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=2: row=['ptq', 20, 5, 5, 13, 0.078125, 0.078125, 2.2676265637079873]\n",
      "j=3: max_bits=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:30,  1.73s/it]\n",
      "4it [24:07, 327.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=3: row=['ptq', 20, 5, 4, 13, 0.03125, 0.03125, 2.193187900384267]\n",
      "x.bit_width=1 > lsbs_to_remove=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [24:10, 210.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=4: row=['ptq', 20, 5, <Exactness.EXACT: 0>, -1, -1, -1, -1, -1]\n",
      "j=5: max_bits=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:47,  1.84s/it]\n",
      "6it [29:03, 290.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5: row=['ptq', 20, 5, <Exactness.APPROXIMATE: 1>, 14, 0.015625, 0.015625, 2.4788689692815145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history2 = run(fp32_mnist, quant_mnist, 'ptq', data_calibration, test_loader, bits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_layers=20, bits=3, compile_type='ptq', compile_function=<function compile_torch_model at 0x7f049a7495a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: max_bits=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [05:05,  1.96s/it]\n",
      "1it [05:10, 310.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: row=['ptq', 20, 3, 7, 9, 0.078125, 0.0625, 2.806963606675466]\n",
      "j=1: max_bits=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [03:53,  1.50s/it]\n",
      "2it [09:08, 267.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1: row=['ptq', 20, 3, 6, 9, 0.109375, 0.09375, 1.6173099716504415]\n",
      "j=2: max_bits=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [03:10,  1.22s/it]\n",
      "3it [12:22, 234.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=2: row=['ptq', 20, 3, 5, 9, 0.09375, 0.09375, 0.8691867828369141]\n",
      "j=3: max_bits=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [02:59,  1.15s/it]\n",
      "4it [15:26, 214.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=3: row=['ptq', 20, 3, 4, 9, 0.046875, 0.046875, 0.7026218215624491]\n",
      "x.bit_width=1 > lsbs_to_remove=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [15:28, 137.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=4: row=['ptq', 20, 3, <Exactness.EXACT: 0>, -1, -1, -1, -1, -1]\n",
      "j=5: max_bits=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [03:15,  1.25s/it]\n",
      "6it [18:48, 188.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5: row=['ptq', 20, 3, <Exactness.APPROXIMATE: 1>, 10, 0.15625, 0.15625, 0.9648106932640076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history2 = run(fp32_mnist, quant_mnist, 'ptq', data_calibration, test_loader, bits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_layers=20, bits=5, compile_type='qat', compile_function=<function compile_brevitas_qat_model at 0x7f049a7496c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: max_bits=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [10:04,  3.88s/it]\n",
      "1it [10:10, 610.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: row=['qat', 20, 5, 7, 16, 0.90625, 0.90625, 7.3796510934829715]\n",
      "j=1: max_bits=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [05:46,  2.22s/it]\n",
      "2it [16:02, 458.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1: row=['qat', 20, 5, 6, 16, 0.984375, 0.984375, 3.0753005305926004]\n",
      "j=2: max_bits=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [05:04,  1.95s/it]\n",
      "3it [21:13, 390.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=2: row=['qat', 20, 5, 5, 16, 0.9375, 0.9375, 2.413205846150716]\n",
      "j=3: max_bits=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [04:26,  1.71s/it]\n",
      "4it [25:47, 344.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=3: row=['qat', 20, 5, 4, 16, 0.515625, 0.421875, 1.767675773302714]\n",
      "x.bit_width=1 > lsbs_to_remove=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [25:51, 221.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=4: row=['qat', 20, 5, <Exactness.EXACT: 0>, -1, -1, -1, -1, -1]\n",
      "x.bit_width=12 > lsbs_to_remove=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [25:54, 259.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5: row=['qat', 20, 5, <Exactness.APPROXIMATE: 1>, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bits = 5\n",
    "nb_layers = 20\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "history = run(fp32_mnist, quant_mnist, 'qat', data_calibration, test_loader, bits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = run(fp32_mnist, quant_mnist, 'qat', data_calibration, test_loader, bits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': 7,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1},\n",
       " {'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': 6,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1},\n",
       " {'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': 5,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1},\n",
       " {'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': 4,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1},\n",
       " {'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': <Exactness.APPROXIMATE: 1>,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1},\n",
       " {'Compile Type': 'qat',\n",
       "  'Number of Layers': 20,\n",
       "  'Bits': 4,\n",
       "  'Threshold': <Exactness.APPROXIMATE: 1>,\n",
       "  'Max Bits': -1,\n",
       "  'Mean FP32 Accuracy': -1,\n",
       "  'Mean Quant Accuracy': -1,\n",
       "  'FHE Timing': -1}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_layers=20, bits=5, compile_type='qat', compile_function=<function compile_brevitas_qat_model at 0x7f19ceed5bd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0: max_bits=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "bits = 5\n",
    "nb_layers = 20\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "\n",
    "\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "\n",
    "history3 = run(fp32_mnist, quant_mnist, 'qat', data_calibration, test_loader, bits=4)\n",
    "history4 = run(fp32_mnist, quant_mnist, 'ptq', data_calibration, test_loader, bits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 4\n",
    "nb_layers = 50\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "\n",
    "\n",
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "\n",
    "history35 = run(fp32_mnist, quant_mnist, 'qat', data_calibration, test_loader, bits=4)\n",
    "history47 = run(fp32_mnist, quant_mnist, 'ptq', data_calibration, test_loader, bits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 50-nb_layers: acc_after_ft_train=98.012% vs acc_after_ft_test=96.855%\n"
     ]
    }
   ],
   "source": [
    "nb_layers = 50\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "checkpoint = torch.load(f\"checkpoints/MNIST/NLP_{nb_layers}/fp32/MNIST_fp32_state_dict.pt\", map_location=device)\n",
    "fp32_mnist.load_state_dict(checkpoint)\n",
    "\n",
    "acc_after_ft_train = torch_inference(fp32_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(fp32_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {fp32_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before fine-tuning: acc_before_ft=9.696%\n",
      "Maximum bit-width in the circuit: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bits, run, nb_layers = 4, True, 50\n",
    "\n",
    "quant_mnist = QuantMNIST(bit=bits, output_size=param[\"output_size\"], nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist = mapping_keys(checkpoint, quant_mnist, device=\"cpu\")\n",
    "acc_before_ft = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "\"\"\"\n",
    "Accuracy before fine-tuning: acc_before_ft=10.286%\n",
    "Maximum bit-width in the circuit: 16\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Accuracy before fine-tuning: {acc_before_ft=:.3%}\")\n",
    "qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/MNIST/NLP_50/quant_mnist_bits=4/MNIST_quant_mnist_bits=4_state_dict.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f\"checkpoints/MNIST/NLP_{nb_layers}/quant_mnist_{bits=}/MNIST_quant_mnist_{bits=}_state_dict.pt\"\n",
    "print(path)\n",
    "quant_mnist = QuantMNIST(bit=bits, nb_layers=nb_layers).to(\"cpu\")\n",
    "quant_mnist.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "# acc_after_ft_train = torch_inference(quant_mnist, train_loader, device=device)\n",
    "# acc_after_ft_test  = torch_inference(quant_mnist, test_loader, device=device)\n",
    "\n",
    "# print(\n",
    "#     f\"With {quant_mnist.bit}-bits and {quant_mnist.nb_layers}-nb_layers: \"\n",
    "#     f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "#     )\n",
    "\n",
    "# qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "# print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: Train loss = 0.4400 VS Test loss = 0.6100 - Accuracy train: 0.8940 VS Accuracy test: 0.8411\n",
      "Epoch  1: Train loss = 0.4530 VS Test loss = 0.3802 - Accuracy train: 0.8917 VS Accuracy test: 0.9366\n",
      "Epoch  2: Train loss = 0.4523 VS Test loss = 0.5532 - Accuracy train: 0.8917 VS Accuracy test: 0.7930\n",
      "Epoch  3: Train loss = 0.4462 VS Test loss = 0.4610 - Accuracy train: 0.8922 VS Accuracy test: 0.9114\n",
      "Epoch  4: Train loss = 0.4488 VS Test loss = 0.5657 - Accuracy train: 0.8912 VS Accuracy test: 0.7489\n",
      "Epoch  5: Train loss = 0.4541 VS Test loss = 0.4020 - Accuracy train: 0.8917 VS Accuracy test: 0.9104\n",
      "Epoch  6: Train loss = 0.4468 VS Test loss = 0.5325 - Accuracy train: 0.8920 VS Accuracy test: 0.8685\n",
      "Epoch  7: Train loss = 0.4451 VS Test loss = 0.4936 - Accuracy train: 0.8929 VS Accuracy test: 0.8282\n",
      "Epoch  8: Train loss = 0.4484 VS Test loss = 0.5095 - Accuracy train: 0.8922 VS Accuracy test: 0.8144\n",
      "Epoch  9: Train loss = 0.4426 VS Test loss = 0.5891 - Accuracy train: 0.8925 VS Accuracy test: 0.7720\n",
      "Epoch 10: Train loss = 0.4487 VS Test loss = 0.4339 - Accuracy train: 0.8924 VS Accuracy test: 0.9341\n",
      "Epoch 11: Train loss = 0.4450 VS Test loss = 0.5444 - Accuracy train: 0.8921 VS Accuracy test: 0.8189\n",
      "Epoch 12: Train loss = 0.4442 VS Test loss = 0.5472 - Accuracy train: 0.8927 VS Accuracy test: 0.8343\n",
      "Epoch 13: Train loss = 0.4475 VS Test loss = 0.4131 - Accuracy train: 0.8922 VS Accuracy test: 0.9317\n",
      "Epoch 14: Train loss = 0.4479 VS Test loss = 0.5178 - Accuracy train: 0.8931 VS Accuracy test: 0.8151\n",
      "100%|| 15/15 [22:17<00:00, 89.16s/it]\n",
      "Save in: checkpoints/MNIST/NLP_50/quant_mnist_bits=4/MNIST_quant_mnist_bits=4_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "assert str(quant_mnist.nb_layers) in param[\"dir\"]\n",
    "\n",
    "if run:\n",
    "    param[\"training\"] = f\"quant_mnist_{bits=}\"\n",
    "    param[\"epochs\"] = 5\n",
    "    param[\"lr\"] = 0.000001\n",
    "    param[\"milestones\"] = []\n",
    "    param[\"gamma\"] = 0.1\n",
    "    quant_mnist = train(quant_mnist, train_loader, test_loader, param, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum bit-width in the circuit: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qmodel = fhe_compatibility(quant_mnist, data_calibration, rounding_threshold_bits=bits)\n",
    "print(f\"Maximum bit-width in the circuit: {qmodel.fhe_circuit.graph.maximum_integer_bit_width()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 100-nb_layers: acc_after_ft_train=68.967% vs acc_after_ft_test=70.092%\n"
     ]
    }
   ],
   "source": [
    "nb_layers = 100\n",
    "\n",
    "param[\"dir\"] =  f\"./checkpoints/MNIST/NLP_{nb_layers}/\"\n",
    "\n",
    "fp32_mnist = Fp32MNIST(param['output_size'], nb_layers=nb_layers).to(device)\n",
    "\n",
    "checkpoint = torch.load(f\"checkpoints/MNIST/NLP_{nb_layers}/fp32/MNIST_fp32_state_dict.pt\", map_location=device)\n",
    "\n",
    "fp32_mnist.load_state_dict(checkpoint)\n",
    "\n",
    "acc_after_ft_train = torch_inference(fp32_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(fp32_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {fp32_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: Train loss = 0.4472 VS Test loss = 0.8814 - Accuracy train: 0.8737 VS Accuracy test: 0.6469\n",
      " 50%|     | 1/2 [00:49<00:49, 49.17s/it]"
     ]
    }
   ],
   "source": [
    "# for name in fp32_mnist:\n",
    "#     if name in mnist_nlp50 and fp32_mnist[name].size() == mnist_nlp50[name].size():\n",
    "#         mnist_nlp50[name].copy_(fp32_mnist[name])\n",
    "\n",
    "# fp32_mnist.load_state_dict(checkpoint)\n",
    "\n",
    "for n, p in list(fp32_mnist.named_parameters())[0: 95]:\n",
    "        p.requires_grad = True\n",
    "\n",
    "# for n, p in list(fp32_mnist.named_parameters())[]:\n",
    "#         p.requires_grad = True\n",
    "\n",
    "run = 1\n",
    "\n",
    "if run:\n",
    "    param[\"training\"] = \"fp32\"\n",
    "    param[\"epochs\"] = 2\n",
    "    param[\"lr\"] = 0.00001\n",
    "    param[\"milestones\"] = []\n",
    "    param[\"gamma\"] = 0.1\n",
    "\n",
    "    fp32_mnist = train(fp32_mnist, train_loader, test_loader, param, device=device)\n",
    "\n",
    "\n",
    "acc_after_ft_train = torch_inference(fp32_mnist, train_loader, device=device)\n",
    "acc_after_ft_test  = torch_inference(fp32_mnist, test_loader, device=device)\n",
    "\n",
    "print(\n",
    "    f\"With {fp32_mnist.nb_layers}-nb_layers: \"\n",
    "    f\"{acc_after_ft_train=:.3%} vs {acc_after_ft_test=:.3%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1069ca3ee43010eb0dc75ae1023d43c37aff1ecf2400458a3da60effb006872e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
