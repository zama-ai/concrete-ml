{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f488541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcelia/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "from time import time\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from utils_dev import *\n",
    "\n",
    "from concrete.ml.torch.hybrid_model import HybridFHEMode\n",
    "from concrete.ml.torch.lora import LoraTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987827f4",
   "metadata": {},
   "source": [
    "# Hybrid Fine-Tuning of LLaMA with LoRA\n",
    "\n",
    "This notebook showcases how to fine-tune the LLaMA-3.2-1B model using LoRA (Low-Rank Adaptation) on the Orca Math Word Problems dataset. The fine-tuning is performed using the _HybridModel_ paradigm, which enables a seamless separation of the computational workload of large language models between the client and a remote server.\n",
    "\n",
    "To preserve data privacy while maintaining performance, this hybrid setup leverages Fully Homomorphic Encryption (FHE) on the remote side. The execution pipeline is structured as follows:\n",
    "\n",
    "- Remote linear layers — which account for the majority of the model's weights and computational cost — are offloaded to a distant machine and executed under encryption using FHE.\n",
    "- Local non-linear layers — such as activation functions — are retained on-premise and executed in plaintext on the client side.\n",
    "- The client’s dataset remains strictly local and is never transferred externally.\n",
    "\n",
    "This approach allows for privacy-preserving fine-tuning and inference, while reducing the computational burden on the client and ensuring that sensitive data never leaves the local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6bb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEFT_ARGS = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "}\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "    \"output_dir\": \"./checkpoints\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"use_cpu\": True,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"lr_scheduler_type\": \"linear\",\n",
    "    \"seed\": SEED,\n",
    "    \"data_seed\": SEED,\n",
    "    \"warmup_steps\": 10,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"prediction_loss_only\": True,\n",
    "    \"report_to\": \"none\",\n",
    "}\n",
    "\n",
    "\n",
    "DEVICE = get_device(force_device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e430a",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The question-answer dataset has been preprocessed and filtered in the `processed_data.py` script and saved to disk for convenience. We load it here directly to simplify the fine-tuning workflow.\n",
    "\n",
    "> ⚠️ If the files are missing, please run `processed_data.py` to regenerate them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d222c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(TOKENIZER)\n",
    "train_dataset = load_from_disk(TRAIN_PATH)\n",
    "test_dataset = load_from_disk(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fc9d8",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer\n",
    "\n",
    "Load the LLaMA model and tokenizer, and test the base model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12782ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: `When you multiply a number by 7, it becomes 98. What is that number?\n",
      "`\n",
      "Response: `A. 0\n",
      "B. 1\n",
      "C. 2\n",
      "D. 3\n",
      "E. 4\n",
      "Answer: B`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, token=HF_TOKEN).to(DEVICE)\n",
    "pretrained_model.config.pad_token_id = pretrained_model.config.eos_token_id\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "PROMPT = \"When you multiply a number by 7, it becomes 98. What is that number?\\n\"\n",
    "_ = generate_and_print(PROMPT, pretrained_model, TOKENIZER, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6180fa",
   "metadata": {},
   "source": [
    "## LoRA Configuration\n",
    "\n",
    "Set up LoRA parameters and apply them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d95791",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(pretrained_model, LoraConfig(**PEFT_ARGS)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756805bb",
   "metadata": {},
   "source": [
    "## Training Arguments\n",
    "\n",
    "Configure the training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7586613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "2025-07-16 08:35:19,187 - INFO - === Starting new training session ===\n",
      "2025-07-16 08:35:19,190 - INFO - Processing '5' Remote Modules.\n",
      "2025-07-16 08:35:19,191 - INFO - Benchmark file already created: '/Users/kcelia/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/client_benchmarks.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA layers detected in the model.\n"
     ]
    }
   ],
   "source": [
    "hf_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(**TRAINING_ARGS),\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "train_dl = hf_trainer.get_train_dataloader()\n",
    "eval_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "\n",
    "hf_trainer.create_optimizer_and_scheduler(len(train_dl) * TRAINING_ARGS[\"num_train_epochs\"])\n",
    "optimizer, lr_scheduler = hf_trainer.optimizer, hf_trainer.lr_scheduler\n",
    "\n",
    "\n",
    "lora_trainer = LoraTrainer(\n",
    "    model=peft_model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=causal_lm_loss,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    training_args=TRAINING_ARGS,\n",
    "    n_layers_to_skip_for_backprop=3,\n",
    "    eval_loader=eval_dl,\n",
    "    eval_metric_fn=metric_fn,\n",
    "    logging_steps=1,\n",
    "    eval_steps=100,\n",
    "    train_log_path=TRAIN_LOG_FILE,\n",
    "    machine_type=\"M4\",\n",
    "    server_remote_address=\"http://13.36.240.77:8001\",\n",
    "    model_name=f\"meta-llama\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f800c0",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling FHE layers: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"
     ]
    }
   ],
   "source": [
    "inputset = get_random_inputset(\n",
    "        vocab_size=VOCAB_SIZE, batch_size=BATCH_SIZE, max_length=MAX_LENGTH, device=DEVICE\n",
    "    )\n",
    "start_time = time()\n",
    "lora_trainer.compile(inputset, n_bits=N_BITS, device=DEVICE)\n",
    "print(f\"Compilation completed under: {time() - start_time:.2f}s using {DEVICE=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd122b1",
   "metadata": {},
   "source": [
    "# Evaluate the model before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b64f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: `When you multiply a number by 7, it becomes 98. What is that number?\n",
      "`\n",
      "Response: `A. 0\n",
      "B. 1\n",
      "C. 2\n",
      "D. 3\n",
      "E. 4\n",
      "Answer: B`\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final perplexity after extended training: 116.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "peft_model.eval()\n",
    "\n",
    "initial_weights = extract_lora_weights(peft_model)\n",
    "\n",
    "initial_metrics = metric_fn(peft_model, eval_dl, PROMPT, EVAL_RESPONSES_FILE, DEVICE)\n",
    "print(f\"Final perplexity after extended training: {initial_metrics['perplexity']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07799c9",
   "metadata": {},
   "source": [
    "## Separate Remote Modules\n",
    "\n",
    "In a hybrid execution setup, we must isolate the parts of the model that will run remotely (typically, the linear layers) from those that will stay on the client side (non-linear layers, activations, etc.).\n",
    "\n",
    "The following line performs this separation by:\n",
    "\n",
    "- Saving the compiled remote modules (linear layers quantized and ready for remote execution),\n",
    "- Removing sensitive information such as calibration data or client-side metadata,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c2d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 08:34:25,986 - INFO - Model saved at compiled_models/meta-llama\n"
     ]
    }
   ],
   "source": [
    "lora_trainer.save_and_clear_private_info(COMPILED_MODELS_PATH, via_mlir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5836667",
   "metadata": {},
   "source": [
    "## Initialize Client-Side Model\n",
    "\n",
    "Here we generate keys and send the public evaluation key to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 08:34:26,520 - INFO - Generating keys...\n",
      "2025-07-16 08:34:27,151 - INFO - Keys generated...\n",
      "2025-07-16 08:34:27,170 - INFO - Saving the public evaluation key at compiled_models/meta-llama/client/public_evaluation_key.serverKey...\n"
     ]
    }
   ],
   "source": [
    "client_path = COMPILED_MODELS_PATH / \"client\"\n",
    "\n",
    "lora_trainer.hybrid_model.init_client(\n",
    "    path_to_clients=client_path, path_to_keys=PATH_TO_CLIENTS_KEYS\n",
    ")\n",
    "\n",
    "# Enable remote FHE mode: linear layers will be executed on the server\n",
    "lora_trainer.hybrid_model.set_fhe_mode(HybridFHEMode.REMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf49af",
   "metadata": {},
   "source": [
    "## Run a Short Fine-Tuning Loop with Remote FHE\n",
    "\n",
    "We fine-tune the model for a few batches using remote FHE mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m limited_batches = get_limited_batches(train_dl, \u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mlora_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimited_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfhe\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mremote\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/lora.py:586\u001b[39m, in \u001b[36mLoraTrainer.train\u001b[39m\u001b[34m(self, train_loader, num_epochs, fhe, device)\u001b[39m\n\u001b[32m    580\u001b[39m     batch = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    581\u001b[39m         item.to(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[32m    582\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch\n\u001b[32m    583\u001b[39m     )\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# Forward pass through the hybrid model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m loss, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhybrid_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfhe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfhe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# Loss scaling and backward is done inside LoraTraining\u001b[39;00m\n\u001b[32m    589\u001b[39m \n\u001b[32m    590\u001b[39m \u001b[38;5;66;03m# Accumulate loss for logging\u001b[39;00m\n\u001b[32m    591\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/hybrid_model.py:919\u001b[39m, in \u001b[36mHybridFHEModel.__call__\u001b[39m\u001b[34m(self, x, fhe)\u001b[39m\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, fhe: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m\"\u001b[39m) -> torch.Tensor:\n\u001b[32m    910\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call method to run the model locally with a fhe mode.\u001b[39;00m\n\u001b[32m    911\u001b[39m \n\u001b[32m    912\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    917\u001b[39m \u001b[33;03m        (torch.Tensor): The output tensor.\u001b[39;00m\n\u001b[32m    918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfhe\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/hybrid_model.py:905\u001b[39m, in \u001b[36mHybridFHEModel.forward\u001b[39m\u001b[34m(self, x, fhe)\u001b[39m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m remote_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.remote_modules.values():\n\u001b[32m    904\u001b[39m         remote_module.progress_callback = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/lora.py:247\u001b[39m, in \u001b[36mLoraTraining.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# Pass inputs and labels to the model\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (\u001b[38;5;28mdict\u001b[39m, UserDict)):\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    249\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.inference_model(*inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/peft/peft_model.py:1845\u001b[39m, in \u001b[36mPeftModelForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[39m\n\u001b[32m   1843\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   1844\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1850\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1851\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1852\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1853\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1854\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1856\u001b[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001b[32m   1857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1858\u001b[39m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:216\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:553\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m output_hidden_states = (\n\u001b[32m    549\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    550\u001b[39m )\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    567\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:441\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    439\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:290\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:231\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m input_shape = hidden_states.shape[:-\u001b[32m1\u001b[39m]\n\u001b[32m    229\u001b[39m hidden_shape = (*input_shape, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m query_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    232\u001b[39m key_states = \u001b[38;5;28mself\u001b[39m.k_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    233\u001b[39m value_states = \u001b[38;5;28mself\u001b[39m.v_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/peft/tuners/lora/layer.py:755\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    753\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.base_layer(x, *args, **kwargs)\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m     torch_result_dtype = result.dtype\n\u001b[32m    758\u001b[39m     lora_A_keys = \u001b[38;5;28mself\u001b[39m.lora_A.keys()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/use_case_examples/deploy_llama_finetuning/.venv_llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/hybrid_model.py:459\u001b[39m, in \u001b[36mRemoteModule.forward\u001b[39m\u001b[34m(self, x, device)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fhe_local_mode == HybridFHEMode.REMOTE:  \u001b[38;5;66;03m# pragma:no cover\u001b[39;00m\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.executor:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m         y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mremote_glwe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m         y = \u001b[38;5;28mself\u001b[39m.remote_call(x, x.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Zama/concrete-ml/src/concrete/ml/torch/hybrid_model.py:579\u001b[39m, in \u001b[36mRemoteModule.remote_glwe_call\u001b[39m\u001b[34m(self, x, device)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Convert quantized data to numpy arrays for encryption.\u001b[39;00m\n\u001b[32m    577\u001b[39m x_q_int = x_q.long().cpu().numpy().astype(numpy.int64).astype(numpy.uint64)\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.private_remote_weights_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    580\u001b[39m path_client = Path(\u001b[38;5;28mself\u001b[39m.private_remote_weights_path).parent / \u001b[33m\"\u001b[39m\u001b[33mclient\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m path_client.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "limited_batches = get_limited_batches(train_dl, 3)\n",
    "lora_trainer.train(limited_batches, fhe=\"remote\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650fea90",
   "metadata": {},
   "source": [
    "# Evaluate the model after fine-tuning\n",
    "\n",
    "We evaluate the model on the validation set to compute its final perplexity, a standard metric for language modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finetuned_weights = extract_lora_weights(peft_model)\n",
    "peft_model.eval()\n",
    "metrics_final = metric_fn(peft_model, eval_dl, PROMPT, EVAL_RESPONSES_FILE, DEVICE)\n",
    "print(f\"Final perplexity after extended training: {metrics_final['perplexity']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb850da",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = pd.read_csv(\"client_benchmarks.csv\", sep=\";\")\n",
    "server = pd.read_csv(\"server_benchmarks.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b310cdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>machine</th>\n",
       "      <th>uid</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>index</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>remote_weight_shape</th>\n",
       "      <th>time_read_key</th>\n",
       "      <th>time_deserialization_key</th>\n",
       "      <th>time_serialization_key</th>\n",
       "      <th>time_storage_key</th>\n",
       "      <th>time_read_input</th>\n",
       "      <th>time_deserialize_input</th>\n",
       "      <th>encrypted_input_size</th>\n",
       "      <th>time_weight_quantization</th>\n",
       "      <th>time_serialization_output</th>\n",
       "      <th>time_matmul</th>\n",
       "      <th>time_packing_output_response</th>\n",
       "      <th>total_add_key_func</th>\n",
       "      <th>total_compute_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key</td>\n",
       "      <td>2025-07-15 19:28:15</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>ade27f60-523a-4e26-b678-63bfddf1192f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:28:50</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>ade27f60-523a-4e26-b678-63bfddf1192f</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>34.905582</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.929621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Key</td>\n",
       "      <td>2025-07-15 19:31:34</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.027247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:32:02</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>28.538269</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.557032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:32:11</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 512)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.304419</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.312503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:32:19</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 512)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>8.446628</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.453925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:32:52</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>32.715363</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.726437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>compute</td>\n",
       "      <td>2025-07-15 19:33:26</td>\n",
       "      <td>cpu</td>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>inference_model.base_model.model.model.layers....</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>530968.0</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>33.900339</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.910840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  endpoint                 date device        machine  \\\n",
       "0      Key  2025-07-15 19:28:15    cpu  g4dn.16xlarge   \n",
       "1  compute  2025-07-15 19:28:50    cpu  g4dn.16xlarge   \n",
       "2      Key  2025-07-15 19:31:34    cpu  g4dn.16xlarge   \n",
       "3  compute  2025-07-15 19:32:02    cpu  g4dn.16xlarge   \n",
       "4  compute  2025-07-15 19:32:11    cpu  g4dn.16xlarge   \n",
       "5  compute  2025-07-15 19:32:19    cpu  g4dn.16xlarge   \n",
       "6  compute  2025-07-15 19:32:52    cpu  g4dn.16xlarge   \n",
       "7  compute  2025-07-15 19:33:26    cpu  g4dn.16xlarge   \n",
       "\n",
       "                                    uid  \\\n",
       "0  ade27f60-523a-4e26-b678-63bfddf1192f   \n",
       "1  ade27f60-523a-4e26-b678-63bfddf1192f   \n",
       "2  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "3  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "5  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "6  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "7  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "\n",
       "                                          layer_name  index input_shape  \\\n",
       "0                                                NaN    NaN         NaN   \n",
       "1  inference_model.base_model.model.model.layers....    0.0  (64, 2048)   \n",
       "2                                                NaN    NaN         NaN   \n",
       "3  inference_model.base_model.model.model.layers....    0.0  (64, 2048)   \n",
       "4  inference_model.base_model.model.model.layers....    1.0  (64, 2048)   \n",
       "5  inference_model.base_model.model.model.layers....    2.0  (64, 2048)   \n",
       "6  inference_model.base_model.model.model.layers....    3.0  (64, 2048)   \n",
       "7  inference_model.base_model.model.model.layers....    4.0  (64, 2048)   \n",
       "\n",
       "  remote_weight_shape  time_read_key  time_deserialization_key  \\\n",
       "0                 NaN       0.009222                  0.023158   \n",
       "1        (2048, 2048)            NaN                       NaN   \n",
       "2                 NaN       0.007196                  0.023966   \n",
       "3        (2048, 2048)            NaN                       NaN   \n",
       "4         (2048, 512)            NaN                       NaN   \n",
       "5         (2048, 512)            NaN                       NaN   \n",
       "6        (2048, 2048)            NaN                       NaN   \n",
       "7        (2048, 2048)            NaN                       NaN   \n",
       "\n",
       "   time_serialization_key  time_storage_key  time_read_input  \\\n",
       "0                0.016631          0.025622              NaN   \n",
       "1                     NaN               NaN         0.000023   \n",
       "2                0.019641          0.027247              NaN   \n",
       "3                     NaN               NaN         0.000009   \n",
       "4                     NaN               NaN         0.000077   \n",
       "5                     NaN               NaN         0.000015   \n",
       "6                     NaN               NaN         0.000024   \n",
       "7                     NaN               NaN         0.000040   \n",
       "\n",
       "   time_deserialize_input  encrypted_input_size  time_weight_quantization  \\\n",
       "0                     NaN                   NaN                       NaN   \n",
       "1                0.000078              530968.0                  0.014169   \n",
       "2                     NaN                   NaN                       NaN   \n",
       "3                0.000084              530968.0                  0.009940   \n",
       "4                0.000136              530968.0                  0.005112   \n",
       "5                0.000051              530968.0                  0.004382   \n",
       "6                0.000305              530968.0                  0.003923   \n",
       "7                0.000094              530968.0                  0.003682   \n",
       "\n",
       "   time_serialization_output  time_matmul  time_packing_output_response  \\\n",
       "0                        NaN          NaN                           NaN   \n",
       "1                   0.000216    34.905582                      0.000091   \n",
       "2                        NaN          NaN                           NaN   \n",
       "3                   0.000159    28.538269                      0.000016   \n",
       "4                   0.000112     8.304419                      0.000014   \n",
       "5                   0.000201     8.446628                      0.000013   \n",
       "6                   0.000240    32.715363                      0.000014   \n",
       "7                   0.000177    33.900339                      0.000024   \n",
       "\n",
       "   total_add_key_func  total_compute_func  \n",
       "0            0.058410                 NaN  \n",
       "1                 NaN           34.929621  \n",
       "2            0.058755                 NaN  \n",
       "3                 NaN           28.557032  \n",
       "4                 NaN            8.312503  \n",
       "5                 NaN            8.453925  \n",
       "6                 NaN           32.726437  \n",
       "7                 NaN           33.910840  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f7c198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>machine</th>\n",
       "      <th>uid</th>\n",
       "      <th>server_remote_address</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>remote_weight_shape</th>\n",
       "      <th>time_encryption_input</th>\n",
       "      <th>time_serialization_input</th>\n",
       "      <th>total_send_input_func</th>\n",
       "      <th>time_deserialization_output</th>\n",
       "      <th>time_decryption_output</th>\n",
       "      <th>time_dequantization_output</th>\n",
       "      <th>total_compute_func</th>\n",
       "      <th>total_timing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-15 19:28:50</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>ade27f60-523a-4e26-b678-63bfddf1192f</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer0.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>34.934256</td>\n",
       "      <td>35.019693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-15 19:32:02</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer0.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>28.560515</td>\n",
       "      <td>28.621814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-15 19:32:11</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer1.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 512)</td>\n",
       "      <td>0.020222</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>8.315347</td>\n",
       "      <td>8.366446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-15 19:32:19</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer2.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 512)</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>8.456745</td>\n",
       "      <td>8.511736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-15 19:32:52</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer3.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>32.729561</td>\n",
       "      <td>32.794023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-07-15 19:33:26</td>\n",
       "      <td>cpu</td>\n",
       "      <td>M4</td>\n",
       "      <td>72751a51-ad40-460f-8b59-32502bac92cb</td>\n",
       "      <td>http://127.0.0.1:8001</td>\n",
       "      <td>remote_weights_layer4.npy</td>\n",
       "      <td>(64, 2048)</td>\n",
       "      <td>(2048, 2048)</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>33.914646</td>\n",
       "      <td>33.994649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date device machine                                   uid  \\\n",
       "0  2025-07-15 19:28:50    cpu      M4  ade27f60-523a-4e26-b678-63bfddf1192f   \n",
       "1  2025-07-15 19:32:02    cpu      M4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "2  2025-07-15 19:32:11    cpu      M4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "3  2025-07-15 19:32:19    cpu      M4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "4  2025-07-15 19:32:52    cpu      M4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "5  2025-07-15 19:33:26    cpu      M4  72751a51-ad40-460f-8b59-32502bac92cb   \n",
       "\n",
       "   server_remote_address                 layer_name input_shape  \\\n",
       "0  http://127.0.0.1:8001  remote_weights_layer0.npy  (64, 2048)   \n",
       "1  http://127.0.0.1:8001  remote_weights_layer0.npy  (64, 2048)   \n",
       "2  http://127.0.0.1:8001  remote_weights_layer1.npy  (64, 2048)   \n",
       "3  http://127.0.0.1:8001  remote_weights_layer2.npy  (64, 2048)   \n",
       "4  http://127.0.0.1:8001  remote_weights_layer3.npy  (64, 2048)   \n",
       "5  http://127.0.0.1:8001  remote_weights_layer4.npy  (64, 2048)   \n",
       "\n",
       "  remote_weight_shape  time_encryption_input  time_serialization_input  \\\n",
       "0        (2048, 2048)               0.020287                  0.000111   \n",
       "1        (2048, 2048)               0.020675                  0.000111   \n",
       "2         (2048, 512)               0.020222                  0.000327   \n",
       "3         (2048, 512)               0.020303                  0.000115   \n",
       "4        (2048, 2048)               0.023046                  0.000047   \n",
       "5        (2048, 2048)               0.023485                  0.000132   \n",
       "\n",
       "   total_send_input_func  time_deserialization_output  time_decryption_output  \\\n",
       "0                    NaN                     0.000145                0.020579   \n",
       "1                    NaN                     0.000094                0.011994   \n",
       "2                    NaN                     0.000060                0.011821   \n",
       "3                    NaN                     0.000055                0.015216   \n",
       "4                    NaN                     0.000095                0.012572   \n",
       "5                    NaN                     0.000118                0.018325   \n",
       "\n",
       "   time_dequantization_output  total_compute_func  total_timing  \n",
       "0                    0.000434           34.934256     35.019693  \n",
       "1                    0.000334           28.560515     28.621814  \n",
       "2                    0.000569            8.315347      8.366446  \n",
       "3                    0.000370            8.456745      8.511736  \n",
       "4                    0.000298           32.729561     32.794023  \n",
       "5                    0.000671           33.914646     33.994649  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76570219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76be2881",
   "metadata": {},
   "source": [
    "This separation is enabled by the HybridFHEModel, allowing efficient encrypted inference while preserving data privacy and minimizing computational load on the client side."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
