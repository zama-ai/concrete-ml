{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "from concrete.ml.dataframe.client import EncryptedDataFrameClient\n",
    "from concrete.ml.dataframe.development import save_deployment\n",
    "from concrete.ml.dataframe.server import EncryptedDataFrameServer\n",
    "\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_DIR = Path(\"deployment\")\n",
    "DEPLOYMENT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "save_deployment(DEPLOYMENT_DIR, \"merge\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path directory for client and server files\n",
    "INPUTS_OUTPUTS_DIR = Path(\"inputs_outputs\")\n",
    "\n",
    "if INPUTS_OUTPUTS_DIR.is_dir():\n",
    "    shutil.rmtree(INPUTS_OUTPUTS_DIR)\n",
    "\n",
    "INPUTS_OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Operator metadata (shared to the server)\n",
    "OP_NAME = \"merge\"\n",
    "N_BITS = 4\n",
    "DTYPE = f\"uint{N_BITS}\"\n",
    "\n",
    "# Client-only parameters\n",
    "LOW = 1\n",
    "HIGH = 2**N_BITS - 1\n",
    "\n",
    "# Pandas kwargs (shared to the server)\n",
    "HOW = \"left\"\n",
    "ON = \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  feat_left_1  feat_left_2  feat_left_3\n",
      "0   1           13            3            8\n",
      "1   2            6            5            8\n",
      "2   3            1            8            9\n",
      "3   4            4            7            2\n",
      "4   5           12            9            6\n",
      "5   6            4            9           10\n",
      "6   7            8           13           14\n",
      "7   8           10           11            9\n",
      "8   9            4            2           10\n",
      "9  10            6            7            5\n"
     ]
    }
   ],
   "source": [
    "# Define the left data-frame\n",
    "n_left = 10\n",
    "n_feat_left = 3\n",
    "\n",
    "dict_left = {\n",
    "    ON: list(range(1, n_left + 1)),\n",
    "}\n",
    "\n",
    "for i in range(n_feat_left):\n",
    "    dict_left[f\"feat_left_{i+1}\"] = list(numpy.random.randint(low=LOW, high=HIGH, size=(n_left,)))\n",
    "\n",
    "df_left = pandas.DataFrame(\n",
    "    dict_left,\n",
    "    dtype=\"int\",\n",
    ")\n",
    "print(df_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  feat_right_1  feat_right_2  feat_right_3  feat_right_4  feat_right_5\n",
      "0   4             4             6             4             4             4\n",
      "1   5             1             1             9            14             8\n",
      "2   6             4             3             2             4             1\n"
     ]
    }
   ],
   "source": [
    "# Define the right data-frame\n",
    "n_right = 3\n",
    "index_shift = 4\n",
    "n_feat_right = 5\n",
    "\n",
    "dict_right = {\n",
    "    ON: list(range(index_shift, n_right + index_shift)),\n",
    "}\n",
    "\n",
    "for i in range(n_feat_right):\n",
    "    dict_right[f\"feat_right_{i+1}\"] = list(\n",
    "        numpy.random.randint(low=LOW, high=HIGH, size=(n_right,))\n",
    "    )\n",
    "\n",
    "df_right = pandas.DataFrame(\n",
    "    dict_right,\n",
    "    dtype=\"int\",\n",
    ")\n",
    "print(df_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the operators to run in the server :\n",
    "# - name: name of the operator\n",
    "# - dtype: value dtype allowed in the data-frame (defines the min/max values as well as the circuit\n",
    "# to use)\n",
    "# - pandas_kwargs: the Pandas arguments to consider for this operator\n",
    "\n",
    "ops_kwargs = [{\"name\": OP_NAME, \"dtype\": DTYPE, \"pandas_kwargs\": {\"how\": HOW, \"on\": ON}}]\n",
    "\n",
    "# Build the client object\n",
    "df_client = EncryptedDataFrameClient(\n",
    "    ops_kwargs=ops_kwargs,\n",
    "    deployment_dir=DEPLOYMENT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and serialize the inputs to send to the server (left data-frame)\n",
    "serialized_input_left = df_client.pre_process_encrypt_serialize(df_left, force_keygen=True)\n",
    "\n",
    "# Retrieve and serialize the operators to send to the server\n",
    "serialized_ops_left = df_client.get_serialized_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    (INPUTS_OUTPUTS_DIR / \"input_left.json\").open(\"w\") as input_left,\n",
    "    (INPUTS_OUTPUTS_DIR / \"ops_left.json\").open(\"w\") as ops_left,\n",
    "):\n",
    "    json.dump(serialized_input_left, input_left)\n",
    "    json.dump(serialized_ops_left, ops_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and serialize the inputs to send to the server (right data-frame)\n",
    "# Do not force keygen here so that both parties use the same set of keys (private and eval)\n",
    "serialized_input_right = df_client.pre_process_encrypt_serialize(df_right, force_keygen=False)\n",
    "\n",
    "# TODO: Retrieve again the operators to send, if we need to check that both parties agree on what to\n",
    "# run, else we can only consider one side for that\n",
    "serialized_ops_right = df_client.get_serialized_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    (INPUTS_OUTPUTS_DIR / \"input_right.json\").open(\"w\") as input_right_file,\n",
    "    (INPUTS_OUTPUTS_DIR / \"ops_right.json\").open(\"w\") as ops_right_file,\n",
    "):\n",
    "    json.dump(serialized_input_right, input_right_file)\n",
    "    json.dump(serialized_ops_right, ops_right_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the server object\n",
    "df_server = EncryptedDataFrameServer(\n",
    "    deployment_dir=DEPLOYMENT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    (INPUTS_OUTPUTS_DIR / \"input_left.json\").open(\"r\") as input_left_file,\n",
    "    (INPUTS_OUTPUTS_DIR / \"input_right.json\").open(\"r\") as input_right_file,\n",
    "    (INPUTS_OUTPUTS_DIR / \"ops_left.json\").open(\"r\") as ops_left_file,\n",
    "    (INPUTS_OUTPUTS_DIR / \"ops_right.json\").open(\"r\") as ops_right_file,\n",
    "):\n",
    "    server_input_left = json.load(input_left_file)\n",
    "    server_input_right = json.load(input_right_file)\n",
    "    server_ops_left = json.load(ops_left_file)\n",
    "    server_ops_right = json.load(ops_right_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FHE execution: 11.97s\n"
     ]
    }
   ],
   "source": [
    "# Run the operators (here: left join only) on the server\n",
    "serialized_server_output = df_server.run(\n",
    "    input_left=server_input_left,\n",
    "    input_right=server_input_right,\n",
    "    ops_left=server_ops_left,\n",
    "    ops_right=server_ops_right,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ((INPUTS_OUTPUTS_DIR / \"server_output.json\").open(\"w\") as server_output_file,):\n",
    "    json.dump(serialized_server_output, server_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ((INPUTS_OUTPUTS_DIR / \"server_output.json\").open(\"r\") as output_file,):\n",
    "    output = json.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the pandas data-frame from the server's output\n",
    "df_joined_cml = df_client.deserialize_decrypt_post_process(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete ML vs Pandas comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_are_equal(df_1, df_2):\n",
    "    \"\"\"Determines if both data-frames are identical, including NaN values.\n",
    "\n",
    "    NaN values have the property of no being equal to one another (ie NaN != NaN). In the following\n",
    "    notebook we want to be able to determine if the CP result is identical to Pandas, including the\n",
    "    NaNs positions (meaning we want to have NaN == NaN)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert_frame_equal(df_1, df_2, check_dtype=False)\n",
    "        return True\n",
    "    except AssertionError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  feat_left_1  feat_left_2  feat_left_3  feat_right_1  feat_right_2  \\\n",
      "0   1           13            3            8           NaN           NaN   \n",
      "1   2            6            5            8           NaN           NaN   \n",
      "2   3            1            8            9           NaN           NaN   \n",
      "3   4            4            7            2           4.0           6.0   \n",
      "4   5           12            9            6           1.0           1.0   \n",
      "5   6            4            9           10           4.0           3.0   \n",
      "6   7            8           13           14           NaN           NaN   \n",
      "7   8           10           11            9           NaN           NaN   \n",
      "8   9            4            2           10           NaN           NaN   \n",
      "9  10            6            7            5           NaN           NaN   \n",
      "\n",
      "   feat_right_3  feat_right_4  feat_right_5  \n",
      "0           NaN           NaN           NaN  \n",
      "1           NaN           NaN           NaN  \n",
      "2           NaN           NaN           NaN  \n",
      "3           4.0           4.0           4.0  \n",
      "4           9.0          14.0           8.0  \n",
      "5           2.0           4.0           1.0  \n",
      "6           NaN           NaN           NaN  \n",
      "7           NaN           NaN           NaN  \n",
      "8           NaN           NaN           NaN  \n",
      "9           NaN           NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# Compute the left-joined data-frame using Pandas\n",
    "df_joined_pandas = pandas.merge(df_left, df_right, on=ON, how=HOW)\n",
    "\n",
    "print(df_joined_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete ML result is equal to Pandas: True \n",
      "\n",
      "     id  feat_left_1  feat_left_2  feat_left_3  feat_right_1  feat_right_2  \\\n",
      "0   1.0         13.0          3.0          8.0           NaN           NaN   \n",
      "1   2.0          6.0          5.0          8.0           NaN           NaN   \n",
      "2   3.0          1.0          8.0          9.0           NaN           NaN   \n",
      "3   4.0          4.0          7.0          2.0           4.0           6.0   \n",
      "4   5.0         12.0          9.0          6.0           1.0           1.0   \n",
      "5   6.0          4.0          9.0         10.0           4.0           3.0   \n",
      "6   7.0          8.0         13.0         14.0           NaN           NaN   \n",
      "7   8.0         10.0         11.0          9.0           NaN           NaN   \n",
      "8   9.0          4.0          2.0         10.0           NaN           NaN   \n",
      "9  10.0          6.0          7.0          5.0           NaN           NaN   \n",
      "\n",
      "   feat_right_3  feat_right_4  feat_right_5  \n",
      "0           NaN           NaN           NaN  \n",
      "1           NaN           NaN           NaN  \n",
      "2           NaN           NaN           NaN  \n",
      "3           4.0           4.0           4.0  \n",
      "4           9.0          14.0           8.0  \n",
      "5           2.0           4.0           1.0  \n",
      "6           NaN           NaN           NaN  \n",
      "7           NaN           NaN           NaN  \n",
      "8           NaN           NaN           NaN  \n",
      "9           NaN           NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# Compte the joined Pandas data-frame to the Concrete ML result\n",
    "print(\"Concrete ML result is equal to Pandas:\", df_are_equal(df_joined_pandas, df_joined_cml), \"\\n\")\n",
    "\n",
    "print(df_joined_cml)"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
